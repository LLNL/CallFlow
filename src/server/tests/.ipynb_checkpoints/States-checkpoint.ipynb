{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for gromov distance computation.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groupBy import groupBy\n",
    "from state import State\n",
    "from callgraph import CallGraph\n",
    "from preprocess import PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux path\n",
    "if platform.system() == \"Linux\":\n",
    "\tcallflow_path = \"/home/vidi/Work/llnl/CallFlow/\"\n",
    "else:\n",
    "\t#Mac OSx path\n",
    "\tcallflow_path = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow\"\n",
    "\n",
    "dataset_path = [\"data/lulesh-1/db-ampi4-100-1\", \"data/lulesh-1/db-ampi4-100-8\"]\n",
    "dataset = ['db-ampi4-100-1', 'db-ampi4-100-8']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graphframes.\n",
    "def create_gfs(file_format, paths):    \n",
    "\tprint(\"Creating graphframes....\")                                                                                             \n",
    "\tret = []                                                                                                                         \n",
    "\tfor idx, path in enumerate(paths):\n",
    "\t\tpath = os.path.abspath(os.path.join(callflow_path, path)) \n",
    "\t\tgf = GraphFrame()   \n",
    "\t\tgf.from_hpctoolkit(path)                                                                            \n",
    "\t\tret.append(gf) \n",
    "\t\tprint(str(idx) + \":\" + path)                                                                                              \n",
    "\treturn ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def lookup(df, node):                                                                                                                    \n",
    "\treturn df.loc[df['node'] == node] \n",
    "\n",
    "def lookup_with_name(df, name):\n",
    "\treturn df.loc[df['name'] == name]\n",
    "\n",
    "def getMaxIncTime(gf):                                                                                                                   \n",
    "\tret = 0.0                                                                                                                            \n",
    "\tfor root in gf.graph.roots:                                                                                                          \n",
    "\t\tret = max(ret, lookup(gf.dataframe, root)['time (inc)'].max())                                                           \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "def getMaxExcTime(gf):                                                                                                                   \n",
    "\tret  = gf.dataframe['CPUTIME (usec) (E)'].max()                                                                                      \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t   \n",
    "def special_lookup(gf, df_index):   \n",
    "\treturn gf.dataframe.loc[gf.dataframe['name'] == df_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter graphframe and graph\n",
    "def filter_gfs(gfs, filterBy):                                                                                                   \n",
    "\t# Create the graph frames from the paths and corresponding format using hatchet                                                  \n",
    "\tfgfs = []                                                                                                                        \n",
    "\t# Filter graphframes based on threshold                                                                                          \n",
    "\tfor idx, gf in enumerate(gfs):                                                                                              \n",
    "\t\tprint(\"Filtering the dataframe!\")                                                                                         \n",
    "\t\tif filterBy == \"IncTime\":                                                                                          \n",
    "\t\t\tmax_inclusive_time = getMaxIncTime(gf)                                                                             \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if(x['time (inc)'] > 0.01*max_inclusive_time) else False)                   \n",
    "\t\telif self.args.filterBy == \"ExcTime\":                                                                                        \n",
    "\t\t\tmax_exclusive_time = getMaxExcTime(gf)                                                                             \n",
    "\t\t\tprint('[Filter] By Exclusive time = {0})'.format(max_exclusive_time))                                                 \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if (x['time'] > 0.01*max_exclusive_time) else False)                  \n",
    "\t\telse:                                                                                                                        \n",
    "\t\t\tprint(\"Not filtering.... Can take forever. Thou were warned\")                                                         \n",
    "\t\t\tfilter_gf = gf                                                                                                           \n",
    "\t\tprint('[Filter] Removed {0} rows.)'.format(gf.dataframe.shape[0] - filter_gf.dataframe.shape[0]))                                                                                                                            \n",
    "\t\tprint(\"Grafting the graph!\")                                                                                            \n",
    "\t\tfilter_gf = filter_gf.squash()                                                                                                \n",
    "\t\tprint(\"[Graft] {0} rows left\".format(filter_gf.dataframe.shape[0])) \n",
    "\t\tfgfs.append(filter_gf)                                              \n",
    "\tprint(fgfs)\n",
    "\treturn fgfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add n_index to the dataframe.\n",
    "def add_n_index(gf):\n",
    "\tgf.dataframe['n_index'] = gf.dataframe.groupby('nid').ngroup()\n",
    "\n",
    "def df_index_name_mapper(graph, df):\n",
    "\tret = {}\n",
    "\tnode_count = 0\n",
    "\troot = graph.roots[0]\n",
    "\tnode_gen = graph.roots[0].traverse()\n",
    "\ttry:\n",
    "\t\twhile root.callpath != None:\n",
    "\t\t\tnode_count += 1\n",
    "\t\t\troot = next(node_gen)\n",
    "\t\t\tret[root.callpath[-1]] = root.df_index\n",
    "\texcept StopIteration:\n",
    "\t\tpass\n",
    "\tfinally:\n",
    "\t\tprint(\"Total nodes in graph: \", node_count)\n",
    "\t\tdel root\n",
    "\treturn ret\n",
    "\n",
    "# add df_index to the dataframe\n",
    "def add_df_index(gf):\n",
    "\tdf_index_name_map = df_index_name_mapper(gf.graph, gf.dataframe)\n",
    "\tgf.dataframe['df_index'] = gf.dataframe['name'].apply(lambda node: df_index_name_map[node] if node in df_index_name_map else 'as ')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-26-67185148990a>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-67185148990a>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    for idx, parent in enumerate(root.parents):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# add callee and caller data into the dataframe\n",
    "def add_callers_and_callee(graph, df):\n",
    "    callees = {}\n",
    "    callers = {}\n",
    "    root = graph.roots[0]\n",
    "    node_gen = graph.roots[0].traverse()\n",
    "    root_df = root.callpath[-1]\n",
    "    callers[root_df] = []\n",
    "    callees[root_df] = []\n",
    "    try:                                                                                                                        \n",
    "        while root.callpath != None:                                                                                            \n",
    "            root = next(node_gen)                                                                                               \n",
    "            if root.parents:                                                                                                     \n",
    "                for idx, parent in enumerate(root.parents):\n",
    "                    root_df = root.callpath[-1]                                                                                     \n",
    "                    parent_df = root.parent.callpath[-1]                                                                            \n",
    "                    if parent_df not in callees:                                                                                    \n",
    "                        callees[parent_df] = []              \n",
    "                    callees[parent_df].append(root_df)                                                                              \n",
    "                    \n",
    "                    if root_df not in callers:                                                                                      \n",
    "                        callers[root_df] = []                                                                                       \n",
    "                    callers[root_df].append(parent_df)                                                                              \t\n",
    "    except StopIteration:                                                                                                       \n",
    "        pass                                                                                                                    \n",
    "    finally:                                                                                                                    \n",
    "        del root                                                                                                                \n",
    "    \n",
    "    df['callees'] = df['name'].apply(lambda node: callees[node] if node in callees else [])                           \n",
    "    df['callers'] = df['name'].apply(lambda node: callers[node] if node in callers else []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process dataframe to add more information. \n",
    "def preprocess(state):\n",
    "\tpreprocess = PreProcess.Builder(state).add_df_index().add_n_index().add_mod_index().add_callers_and_callees().add_show_node().add_vis_node_name().update_module_name().clean_lib_monitor().build() \n",
    "\n",
    "\n",
    "#NetworkX stuff.\n",
    "def create_nx_graph(state):\n",
    "\tg = nx.DiGraph()\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(dataset_path):\n",
    "\tdataset = []\n",
    "\tfor idx, path in enumerate(dataset_path):\n",
    "\t\tdataset.append(path.split('/')[0])\n",
    "\n",
    "\tgfs = create_gfs('hpctoolkit', dataset_path)\n",
    "\t# filtered graph frames.\n",
    "\tfgfs = filter_gfs(gfs, 'IncTime')  \n",
    "\treturn fgfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphframes....\n",
      "0:/home/vidi/Work/llnl/CallFlow/data/hpctoolkit-lulesh-2\n",
      "Filtering the dataframe!\n",
      "[Filter] Removed 1204 rows.)\n",
      "Grafting the graph!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vidi/Work/llnl/CallFlow/src/hatchet/hatchet/graphframe.py:176: FutureWarning: 'node' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  num_rows_df = len(self.dataframe.groupby(['node']))\n",
      "/home/vidi/Work/llnl/CallFlow/src/hatchet/hatchet/graphframe.py:268: FutureWarning: 'rank' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  agg_df = new_dataframe.groupby(index_names).agg(agg_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graft] 1274 rows left\n",
      "[<hatchet.graphframe.GraphFrame object at 0x7f907430f4a8>]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = [\"data/hpctoolkit-lulesh-2\"]\n",
    "fgfs = main(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    states = []\n",
    "    for idx, fgf in enumerate(fgfs):\n",
    "        print(\"Shape of the dataframe from graph ({0}): {1}\".format(dataset[idx], fgf.dataframe.shape))\n",
    "        state = State(fgf)\n",
    "        preprocess(state)\n",
    "#         groupBy(state, 'module')\n",
    "        print(state)\n",
    "        states.append(state)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe from graph (db-ampi4-100-1): (1274, 13)\n",
      "Total nodes in the graph 1275\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d8a334a2e7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-c879fd41161b>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of the dataframe from graph ({0}): {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#         groupBy(state, 'module')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b6fd1508e52f>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pre-process dataframe to add more information.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_df_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mod_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callers_and_callees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_show_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vis_node_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_lib_monitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/llnl/CallFlow/src/server/tests/preprocess.py\u001b[0m in \u001b[0;36madd_callers_and_callees\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallpath\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                         \u001b[0mroot_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                         \u001b[0mparent_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "states = process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_times = {}\n",
    "for idx, state in enumerate(states):\n",
    "    pivot = pd.pivot_table(state.df, values=['CPUTIME (usec) (I)'], index=['module'], columns=['rank'])\n",
    "    for idx, row in enumerate(pivot.iterrows()):\n",
    "        if(row[0] not in aggr_times):\n",
    "            aggr_times[row[0]] = []\n",
    "        aggr_times[row[0]].append(row[1].mean())\n",
    "print(aggr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = {\n",
    "    \"lulesh2.0\" :{\n",
    "        \"name\" : \"lulesh\",\n",
    "        \"files\" : [ \"mpi-linux-x86_64-ifort-mpicxx/tmp/\", \"mpi-linux-x86_64-ifort-mpicxx/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/ck-libs/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/conv-libs/\"],\n",
    "        \"functions\" : [] \n",
    "    },\n",
    "    \"libmpi.so.12.0.5\" :{\n",
    "        \"name\" : \"MPI\",\n",
    "        \"files\" : [\"../src/mpi/\"],\n",
    "        \"functions\" : []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(df, keys, metric = 'mean'):\n",
    "    # Groups data by the keys provided\n",
    "    groups = df.groupby(keys)\n",
    "    measure = getattr(groups, metric)\n",
    "    data = measure() \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = states[0].df\n",
    "\n",
    "def rename_module_names(df, props):\n",
    "    module_names = list(props.keys())\n",
    "    for module_name in module_names:\n",
    "        rename_to = props[module_name]['name']\n",
    "        files = props[module_name]['files']\n",
    "        function = props[module_name]['functions']\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.module:\n",
    "                if(row.module == module_name):\n",
    "                    df.set_value(idx, 'module', rename_to)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        print(df['file'].str.contains(files[0], regex=True))\n",
    "\n",
    "    print(df['module'].unique().tolist())\n",
    "\n",
    "\n",
    "rename_module_names(df, props)\n",
    "print(df[df['module']=='Unkno']['name'].unique().tolist())\n",
    "group_df = groupby(df, ['name', 'rank'])\n",
    "print(group_df)\n",
    "for idx, row in df.iterrows():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint plot of the Inclusive and Exclusive times.\n",
    "df = states[0].df\n",
    "df2 = states[1].df\n",
    "root_max_df = 107348942.00\n",
    "root_max_df2 = 145114370.00\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df.loc[(df['time (inc)'] < 0.10*107348942.00) &\n",
    "                     (df['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df2.loc[(df2['time (inc)'] < 0.10*145114370.00) &\n",
    "                     (df2['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
