{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for gromov distance computation.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groupBy import groupBy\n",
    "from state import State\n",
    "from callgraph import CallGraph\n",
    "from preprocess import PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux path\n",
    "if platform.system() == \"Linux\":\n",
    "\tcallflow_path = \"/home/vidi/Work/llnl/CallFlow/\"\n",
    "else:\n",
    "\t#Mac OSx path\n",
    "\tcallflow_path = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow\"\n",
    "\n",
    "dataset_path = [\"data/lulesh-1/db-ampi4-100-1\", \"data/lulesh-1/db-ampi4-100-8\"]\n",
    "dataset = ['db-ampi4-100-1', 'db-ampi4-100-8']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graphframes.\n",
    "def create_gfs(file_format, paths):    \n",
    "\tprint(\"Creating graphframes....\")                                                                                             \n",
    "\tret = []                                                                                                                         \n",
    "\tfor idx, path in enumerate(paths):\n",
    "\t\tpath = os.path.abspath(os.path.join(callflow_path, path)) \n",
    "\t\tgf = GraphFrame()   \n",
    "\t\tgf.from_hpctoolkit(path, 3)                                                                            \n",
    "\t\tret.append(gf) \n",
    "\t\tprint(str(idx) + \":\" + path)                                                                                              \n",
    "\treturn ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def lookup(df, node):                                                                                                                    \n",
    "\treturn df.loc[df['node'] == node] \n",
    "\n",
    "def lookup_with_name(df, name):\n",
    "\treturn df.loc[df['name'] == name]\n",
    "\n",
    "def getMaxIncTime(gf):                                                                                                                   \n",
    "\tret = 0.0                                                                                                                            \n",
    "\tfor root in gf.graph.roots:                                                                                                          \n",
    "\t\tret = max(ret, lookup(gf.dataframe, root)['CPUTIME (usec) (I)'].max())                                                           \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "def getMaxExcTime(gf):                                                                                                                   \n",
    "\tret  = gf.dataframe['CPUTIME (usec) (E)'].max()                                                                                      \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t   \n",
    "def special_lookup(gf, df_index):   \n",
    "\treturn gf.dataframe.loc[gf.dataframe['name'] == df_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter graphframe and graph\n",
    "def filter_gfs(gfs, filterBy):                                                                                                   \n",
    "\t# Create the graph frames from the paths and corresponding format using hatchet                                                  \n",
    "\tfgfs = []                                                                                                                        \n",
    "\t# Filter graphframes based on threshold                                                                                          \n",
    "\tfor idx, gf in enumerate(gfs):                                                                                              \n",
    "\t\tprint(\"Filtering the dataframe!\")                                                                                         \n",
    "\t\tif filterBy == \"IncTime\":                                                                                          \n",
    "\t\t\tmax_inclusive_time = getMaxIncTime(gf)                                                                             \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if(x['CPUTIME (usec) (I)'] > 0.01*max_inclusive_time) else False)                   \n",
    "\t\telif self.args.filterBy == \"ExcTime\":                                                                                        \n",
    "\t\t\tmax_exclusive_time = getMaxExcTime(gf)                                                                             \n",
    "\t\t\tprint('[Filter] By Exclusive time = {0})'.format(max_exclusive_time))                                                 \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if (x['CPUTIME (usec) (E)'] > 0.01*max_exclusive_time) else False)                  \n",
    "\t\telse:                                                                                                                        \n",
    "\t\t\tprint(\"Not filtering.... Can take forever. Thou were warned\")                                                         \n",
    "\t\t\tfilter_gf = gf                                                                                                           \n",
    "\t\tprint('[Filter] Removed {0} rows.)'.format(gf.dataframe.shape[0] - filter_gf.dataframe.shape[0]))                                                                                                                            \n",
    "\t\tprint(\"Grafting the graph!\")                                                                                            \n",
    "\t\tfilter_gf = filter_gf.graft()                                                                                                \n",
    "\t\tprint(\"[Graft] {0} rows left\".format(filter_gf.dataframe.shape[0])) \n",
    "\t\tfgfs.append(filter_gf)                                              \n",
    "\tprint(fgfs)\n",
    "\treturn fgfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add n_index to the dataframe.\n",
    "def add_n_index(gf):\n",
    "\tgf.dataframe['n_index'] = gf.dataframe.groupby('nid').ngroup()\n",
    "\n",
    "def df_index_name_mapper(graph, df):\n",
    "\tret = {}\n",
    "\tnode_count = 0\n",
    "\troot = graph.roots[0]\n",
    "\tnode_gen = graph.roots[0].traverse()\n",
    "\ttry:\n",
    "\t\twhile root.callpath != None:\n",
    "\t\t\tnode_count += 1\n",
    "\t\t\troot = next(node_gen)\n",
    "\t\t\tret[root.callpath[-1]] = root.df_index\n",
    "\texcept StopIteration:\n",
    "\t\tpass\n",
    "\tfinally:\n",
    "\t\tprint(\"Total nodes in graph: \", node_count)\n",
    "\t\tdel root\n",
    "\treturn ret\n",
    "\n",
    "# add df_index to the dataframe\n",
    "def add_df_index(gf):\n",
    "\tdf_index_name_map = df_index_name_mapper(gf.graph, gf.dataframe)\n",
    "\tgf.dataframe['df_index'] = gf.dataframe['name'].apply(lambda node: df_index_name_map[node] if node in df_index_name_map else 'as ')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callee and caller data into the dataframe\n",
    "def add_callers_and_callee(graph, df):\n",
    "\tcallees = {}\n",
    "\tcallers = {}\n",
    "\troot = graph.roots[0]\n",
    "\tnode_gen = graph.roots[0].traverse()\n",
    "\troot_df = root.callpath[-1]\n",
    "\tcallers[root_df] = []\n",
    "\tcallees[root_df] = []\n",
    "\ttry:                                                                                                                        \n",
    "\t\twhile root.callpath != None:                                                                                            \n",
    "\t\t\troot = next(node_gen)                                                                                               \n",
    "\t\t\tif root.parent:                                                                                                     \n",
    "\t\t\t\troot_df = root.callpath[-1]                                                                                     \n",
    "\t\t\t\tparent_df = root.parent.callpath[-1]                                                                            \n",
    "\t\t\t\tif parent_df not in callees:                                                                                    \n",
    "\t\t\t\t\tcallees[parent_df] = []              \n",
    "\t\t\t\tcallees[parent_df].append(root_df)                                                                              \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\tif root_df not in callers:                                                                                      \n",
    "\t\t\t\t\tcallers[root_df] = []                                                                                       \n",
    "\t\t\t\tcallers[root_df].append(parent_df)                                                                              \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\texcept StopIteration:                                                                                                       \n",
    "\t\tpass                                                                                                                    \n",
    "\tfinally:                                                                                                                    \n",
    "\t\tdel root                                                                                                                \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\tdf['callees'] = df['name'].apply(lambda node: callees[node] if node in callees else [])                           \n",
    "\tdf['callers'] = df['name'].apply(lambda node: callers[node] if node in callers else []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process dataframe to add more information. \n",
    "def preprocess(state):\n",
    "\tpreprocess = PreProcess.Builder(state).add_df_index().add_n_index().add_mod_index().add_path().add_callers_and_callees().add_show_node().add_vis_node_name().update_module_name().clean_lib_monitor().build() \n",
    "\n",
    "\n",
    "#NetworkX stuff.\n",
    "def create_nx_graph(state):\n",
    "\tg = nx.DiGraph()\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(dataset_path):\n",
    "\tdataset = []\n",
    "\tfor idx, path in enumerate(dataset_path):\n",
    "\t\tdataset.append(path.split('/')[0])\n",
    "\n",
    "\tgfs = create_gfs('hpctoolkit', dataset_path)\n",
    "\t# filtered graph frames.\n",
    "\tfgfs = filter_gfs(gfs, 'IncTime')  \n",
    "\treturn fgfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphframes....\n",
      "0:/home/vidi/Work/llnl/CallFlow/data/lulesh-1/db-ampi4-100-1\n",
      "1:/home/vidi/Work/llnl/CallFlow/data/lulesh-1/db-ampi4-100-8\n",
      "Filtering the dataframe!\n",
      "[Filter] Removed 55333 rows.)\n",
      "Grafting the graph!\n",
      "[Graft] 254 rows left\n",
      "Filtering the dataframe!\n",
      "[Filter] Removed 90008 rows.)\n",
      "Grafting the graph!\n",
      "[Graft] 259 rows left\n",
      "[<hatchet.graphframe.GraphFrame object at 0x7f2169456f28>, <hatchet.graphframe.GraphFrame object at 0x7f2154ab2c88>]\n",
      "[<hatchet.graphframe.GraphFrame object at 0x7f2169456f28>, <hatchet.graphframe.GraphFrame object at 0x7f2154ab2c88>]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = [\"data/lulesh-1/db-ampi4-100-1\", \"data/lulesh-1/db-ampi4-100-8\"]\n",
    "fgfs = main(dataset_path)\n",
    "print(fgfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    states = []\n",
    "    for idx, fgf in enumerate(fgfs):\n",
    "        print(\"Shape of the dataframe from graph ({0}): {1}\".format(dataset[idx], fgf.dataframe.shape))\n",
    "        state = State(fgf)\n",
    "        preprocess(state)\n",
    "        groupBy(state, 'module')\n",
    "        print(state)\n",
    "        states.append(state)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe from graph (db-ampi4-100-1): (254, 21)\n",
      "Total nodes in the graph 10881\n",
      "19.70563530921936\n",
      "<state.State object at 0x7f2154aacda0>\n",
      "Shape of the dataframe from graph (db-ampi4-100-8): (259, 21)\n",
      "Total nodes in the graph 18138\n",
      "31.569156885147095\n",
      "<state.State object at 0x7f21c406fc50>\n"
     ]
    }
   ],
   "source": [
    "states = process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unknown load module>': [65444558.666666664, 50135406.333333336], 'Unkno': [4887682.488575269, 4429995.717948718], 'libc-2.17.so': [10534435.38095238, 4227144.791666667], 'lulesh2.0': [16021569.040096618, 12914692.65116279]}\n"
     ]
    }
   ],
   "source": [
    "aggr_times = {}\n",
    "for idx, state in enumerate(states):\n",
    "    pivot = pd.pivot_table(state.df, values=['CPUTIME (usec) (I)'], index=['module'], columns=['rank'])\n",
    "    for idx, row in enumerate(pivot.iterrows()):\n",
    "        if(row[0] not in aggr_times):\n",
    "            aggr_times[row[0]] = []\n",
    "        aggr_times[row[0]].append(row[1].mean())\n",
    "print(aggr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = {\n",
    "    \"lulesh2.0\" :{\n",
    "        \"name\" : \"lulesh\",\n",
    "        \"files\" : [ \"mpi-linux-x86_64-ifort-mpicxx/tmp/\", \"mpi-linux-x86_64-ifort-mpicxx/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/ck-libs/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/conv-libs/\"],\n",
    "        \"functions\" : [] \n",
    "    },\n",
    "    \"libmpi.so.12.0.5\" :{\n",
    "        \"name\" : \"MPI\",\n",
    "        \"files\" : [\"../src/mpi/\"],\n",
    "        \"functions\" : []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(df, keys, metric = 'mean'):\n",
    "    # Groups data by the keys provided\n",
    "    groups = df.groupby(keys)\n",
    "    measure = getattr(groups, metric)\n",
    "    data = measure() \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = states[0].df\n",
    "\n",
    "def rename_module_names(df, props):\n",
    "    module_names = list(props.keys())\n",
    "    for module_name in module_names:\n",
    "        rename_to = props[module_name]['name']\n",
    "        files = props[module_name]['files']\n",
    "        function = props[module_name]['functions']\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.module:\n",
    "                if(row.module == module_name):\n",
    "                    df.set_value(idx, 'module', rename_to)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        print(df['file'].str.contains(files[0], regex=True))\n",
    "\n",
    "    print(df['module'].unique().tolist())\n",
    "\n",
    "\n",
    "rename_module_names(df, props)\n",
    "print(df[df['module']=='Unkno']['name'].unique().tolist())\n",
    "group_df = groupby(df, ['name', 'rank'])\n",
    "print(group_df)\n",
    "for idx, row in df.iterrows():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint plot of the Inclusive and Exclusive times.\n",
    "df = states[0].df\n",
    "df2 = states[1].df\n",
    "root_max_df = 107348942.00\n",
    "root_max_df2 = 145114370.00\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df.loc[(df['time (inc)'] < 0.10*107348942.00) &\n",
    "                     (df['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df2.loc[(df2['time (inc)'] < 0.10*145114370.00) &\n",
    "                     (df2['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
