{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarus/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py:855: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "/Users/jarus/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py:846: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 2.2 and will be removed in 3.1.\n",
      "  \"2.2\", name=key, obj_type=\"rcparam\", addendum=addendum)\n",
      "/Users/jarus/miniconda3/lib/python3.6/site-packages/seaborn/apionly.py:9: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn.apionly as sns\n",
    "import igraph\n",
    "import platform\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for gromov distance computation.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from actions.groupBy import groupBy\n",
    "from state import State\n",
    "from preprocess import PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets and create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str_with_Node(df, graph):\n",
    "        mapper = {}\n",
    "        def dfs_recurse(root):\n",
    "            for node in root.children: \n",
    "                mapper[node.callpath[-1]] = Node(node.nid, node.callpath, None)\n",
    "                dfs_recurse(node)\n",
    "        for root in graph.roots:\n",
    "            mapper[root.callpath[-1]] = Node(root.nid, root.callpath, None)\n",
    "            dfs_recurse(root)\n",
    "        df['node'] = df['node'].apply(lambda node: mapper[node] if node in mapper else '')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gf(name):\n",
    "    state = State()\n",
    "    dirname = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/src/server/.callflow\"\n",
    "    df_filepath = dirname + '/' + name +  '/filter_df.csv'\n",
    "    entire_df_filepath = dirname + '/' + name + '/entire_df.csv'\n",
    "    graph_filepath = dirname + '/' + name + '/filter_graph.json'\n",
    "    entire_graph_filepath = dirname + '/' + name + '/entire_graph.json'   \n",
    "\n",
    "    with open(graph_filepath, 'r') as graphFile:\n",
    "        data = json.load(graphFile)\n",
    "\n",
    "    state.gf = GraphFrame()\n",
    "    state.gf.from_literal(data)\n",
    "\n",
    "    with open(entire_graph_filepath, 'r') as entire_graphFile:\n",
    "        entire_data = json.load(entire_graphFile)\n",
    "            \n",
    "    state.entire_gf = GraphFrame()\n",
    "    state.entire_gf.from_literal(entire_data)\n",
    "\n",
    "    state.df = pd.read_csv(df_filepath)\n",
    "    state.entire_df = pd.read_csv(entire_df_filepath)\n",
    "\n",
    "    state.graph = state.gf.graph\n",
    "    state.entire_graph = state.entire_gf.graph\n",
    "\n",
    "    state.map = state.node_hash_mapper()\n",
    "\n",
    "    # Print the module group by information. \n",
    "    # print(state.df.groupby(['module']).agg(['mean','count']))\n",
    "\n",
    "    # replace df['node'] from str to the Node object.\n",
    "    state.df = replace_str_with_Node(state.df, state.graph)\n",
    "    state.entire_df = replace_str_with_Node(state.entire_df, state.entire_graph)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<state.State object at 0x1a26c8c748>, <state.State object at 0x182272eb00>]\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"kripke-impi\", \"kripke-mvapich2\"]\n",
    "states = []\n",
    "for idx, dataset_name in enumerate(datasets):\n",
    "    state = read_gf(dataset_name)\n",
    "    states.append(state)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nxGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bf28325f13dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnxGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_nx_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nxGraph' is not defined"
     ]
    }
   ],
   "source": [
    "states = nxGraph.create_nx_graph(states)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify topology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_target_to_adj_matrix(arr):\n",
    "    key_map = {}\n",
    "    x_arr = []\n",
    "    for idx, elem in enumerate(arr):\n",
    "        if elem['source'] not in x_arr and elem['source'] not in key_map:\n",
    "            key_map[elem['source']] = len(x_arr)\n",
    "            x_arr.append(elem['source'])\n",
    "        if elem['target'] not in x_arr and elem['target'] not in key_map:\n",
    "            key_map[elem['target']] = len(x_arr)\n",
    "            x_arr.append(elem['target'])\n",
    "            \n",
    "    x, y = len(list(set(x_arr))), len(list(set(x_arr)))\n",
    "    adj_matrix = np.zeros(shape=(x, y))\n",
    "    \n",
    "    for idx, elem in enumerate(arr):\n",
    "        if(elem['source'] != -1):\n",
    "            source_elem_pos = key_map[elem['source']]\n",
    "        if(elem['target'] != -1):\n",
    "            target_elem_pos = key_map[elem['target']]\n",
    "        adj_matrix[source_elem_pos][target_elem_pos] = elem['weight']\n",
    "    return adj_matrix, key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_topology(state, module):\n",
    "    g = state.g\n",
    "    print(g)\n",
    "    topology = nx.Graph()\n",
    "    source_target_data = []\n",
    "    nodes = [x for x,y in g.nodes(data=True) if y['module'] == [module]]\n",
    "    entry_node = nodes[0]\n",
    "    for idx, node in enumerate(nodes):\n",
    "        hierarchy_pd = pd.DataFrame(columns=['source', 'target', 'weight', 'level', 'type'])\n",
    "        neighbors = sorted(g[node].items(), key=lambda edge: edge[1]['weight'])\n",
    "        print(neighbors)\n",
    "        for idx, n in enumerate(neighbors):\n",
    "            source_node = node\n",
    "            target_node = n[0]\n",
    "            weight = n[1]['weight']\n",
    "            level = idx\n",
    "            curr_module = state.df[state.df['name'] == n[0]]['module'].unique()[0]\n",
    "            #print(n[0], curr_module)\n",
    "            if(curr_module != module):\n",
    "                type_node = 'exit'\n",
    "                level = -1\n",
    "                #print('{0} is an exit node'.format(n[0]))\n",
    "            else:\n",
    "                type_node = 'normal'\n",
    "            source_target_data.append({\n",
    "                    \"source\": source_node,\n",
    "                    \"target\": target_node,\n",
    "                    \"weight\": weight,\n",
    "                    \"level\": level,\n",
    "                    \"type\": type_node\n",
    "            })\n",
    "    topology_adj_matrix, topology_key_map = source_target_to_adj_matrix(source_target_data)\n",
    "    #hierarchy_adj_matrix[1][1] = 0.0\n",
    "    #print(nx.find_cycle(state.hg, orientation=\"original\"))\n",
    "    #print(nx.is_tree(state.hg))\n",
    "    topology_df = nx.from_numpy_matrix(topology_adj_matrix)\n",
    "    \n",
    "    return topology_df, topology_key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hierarchy(state):\n",
    "    pos = hierarchy_pos(state.hierarchy, 1)\n",
    "    nx.draw(state.bfs_tree, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "    return source_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-178a574c0eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeymap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mverify_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-178a574c0eae>\u001b[0m in \u001b[0;36mverify_topology\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'libc-2.17.so'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeymap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_topology\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b775553b472e>\u001b[0m in \u001b[0;36mmodule_topology\u001b[0;34m(state, module)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtopology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msource_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mentry_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "def verify_topology(states):\n",
    "    module = 'libc-2.17.so'\n",
    "    for idx, state in enumerate(states):\n",
    "        state.hierarchy, keymap = module_topology(state, module)\n",
    "        print(state.hierarchy.nodes())\n",
    "        print(state.hierarchy.edges())\n",
    "        for idx, key in enumerate(keymap):\n",
    "            print(key, keymap[key], state.df[state.df['name'] == key]['module'].tolist()[0])\n",
    "\n",
    "verify_topology(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9cd08e1f0bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lulesh2.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_flow_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_flow_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9cd08e1f0bba>\u001b[0m in \u001b[0;36mcreate_flow_matrix\u001b[0;34m(state, module)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_flow_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mall_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# nodesInModule = filter(lambda (n, d): d['module'] == start_node, g.nodes(data=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "def create_flow_matrix(state, module):\n",
    "    g = state.g\n",
    "    all_nodes = g.nodes(data=True)\n",
    "    nodes = [x for x,y in g.nodes(data=True) if y['module'] == [module]]\n",
    "    # nodesInModule = filter(lambda (n, d): d['module'] == start_node, g.nodes(data=True))\n",
    "    state.nodeKey = {}\n",
    "    for idx, node in enumerate(all_nodes):\n",
    "        state.nodeKey[node[0]] = idx\n",
    "    \n",
    "    flow_matrix = np.zeros(shape=(len(all_nodes),len(all_nodes)))\n",
    "    flow_matrix.astype(float)\n",
    "\n",
    "    root_inc = g.node[nodes[0]]['time']\n",
    "    \n",
    "    for idx, node in enumerate(nodes):\n",
    "        neighbors = sorted(g[node].items(), key=lambda edge: edge[1]['weight'])\n",
    "        for idx, n in enumerate(neighbors):\n",
    "            sourceKey = int(state.nodeKey[node])\n",
    "#            print(state.df[state.df['node' == n[0]]])\n",
    "            targetKey = int(state.nodeKey[n[0]])\n",
    "            weight = n[1]['weight']\n",
    "            flow_matrix[sourceKey][targetKey] = n[1]['weight']/(1.0*root_inc)\n",
    "    return flow_matrix\n",
    "\n",
    "module = 'lulesh2.0'\n",
    "for idx, state in enumerate(states):\n",
    "    state.flow_matrix = create_flow_matrix(state, module)\n",
    "    plt.matshow(state.flow_matrix)\n",
    "    np.append(np_flow_matrix, state.flow_matrix)\n",
    "fm = np.array([states[0].flow_matrix, states[1].flow_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(variable):\n",
    "    n_bins = 2\n",
    "    N, bins, patches = plt.hist(variable, bins=n_bins)\n",
    "    #fracs = N / N.max()\n",
    "    #norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "    #for thisfrac, thispatch in zip(fracs, patches):\n",
    "    #    color = plt.cm.viridis(norm(thisfrac))\n",
    "    #    thispatch.set_facecolor(color)\n",
    "    #plt.yaxis.set_major_formatter(PercentFormatter(xmax=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Spatial distance between each node in the flow matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = len(states)\n",
    "\n",
    "n_samples = 40\n",
    "ns = [len(fm[s]) for s in range(S)]\n",
    "\n",
    "Cs = [sp.spatial.distance.cdist(fm[s], fm[s]) for s in range(S)]\n",
    "Cs = [cs / cs.max() for cs in Cs]\n",
    "\n",
    "print(Cs)\n",
    "ps = [ot.unif(ns[s]) for s in range(S)]\n",
    "p = ot.unif(n_samples)\n",
    "\n",
    "histogram(Cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gromov wassertsteing barycenter calculation\n",
    "\n",
    "By barycenter they mean the design of an “average” or barycenter of similarity matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(variable):\n",
    "    plt.plot(variable[0], variable[1], 'o', label=str(variable))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smacof_mds(C, dim, max_iter=3000, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Returns an interpolated point cloud following the dissimilarity matrix C\n",
    "    using SMACOF multidimensional scaling (MDS) in specific dimensionned\n",
    "    target space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C : ndarray, shape (ns, ns)\n",
    "        dissimilarity matrix\n",
    "    dim : int\n",
    "          dimension of the targeted space\n",
    "    max_iter :  int\n",
    "        Maximum number of iterations of the SMACOF algorithm for a single run\n",
    "    eps : float\n",
    "        relative tolerance w.r.t stress to declare converge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npos : ndarray, shape (R, dim)\n",
    "           Embedded coordinates of the interpolated point cloud (defined with\n",
    "           one isometry)\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.RandomState(seed=3)\n",
    "\n",
    "    mds = manifold.MDS(\n",
    "        dim,\n",
    "        max_iter=max_iter,\n",
    "        eps=1e-9,\n",
    "        dissimilarity='precomputed',\n",
    "        n_init=1)\n",
    "    pos = mds.fit(C).embedding_\n",
    "\n",
    "    nmds = manifold.MDS(\n",
    "        2,\n",
    "        max_iter=max_iter,\n",
    "        eps=1e-9,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        random_state=rng,\n",
    "        n_init=1)\n",
    "    npos = nmds.fit_transform(C, init=pos)\n",
    "\n",
    "    return npos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdast = [[float(i) / 3, float(3 - i) / 3] for i in [1, 2]]\n",
    "Ct01 = [0 for i in range(2)]\n",
    "for i in range(S):\n",
    "    Ct01[i] = ot.gromov.gromov_barycenters(n_samples, [Cs[0], Cs[1]],\n",
    "                                           [ps[0], ps[1]\n",
    "                                            ], p, lambdast[i], 'square_loss',  # 5e-4,\n",
    "                                           max_iter=100, tol=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = PCA(n_components=2)\n",
    "npos = [0, 0]\n",
    "npos = [smacof_mds(Cs[s], 2) for s in range(S)]\n",
    "\n",
    "npost01 = [0, 0]\n",
    "npost01 = [smacof_mds(Ct01[s], 2) for s in range(2)]\n",
    "npost01 = [clf.fit_transform(npost01[s]) for s in range(2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Ct01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(npost01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx01min = npos[0][0][0]\n",
    "nx01max = npos[0][0][0]\n",
    "ny01min = npos[0][1][1]\n",
    "ny01max = npos[0][1][1]\n",
    "\n",
    "nx02min = npos[1][0][0]\n",
    "nx02max = npos[1][0][0]\n",
    "ny02min = npos[1][1][1]\n",
    "ny02max = npos[1][1][1]\n",
    "\n",
    "for idx, arr in enumerate(npos):\n",
    "    if arr[0][0] < nx01min:\n",
    "        nx01min = arr[0][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[0][1] > nx01max:\n",
    "        nx01max = arr[0][1]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][0] < ny01min:\n",
    "        ny01min = arr[1][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][1] > ny01max:\n",
    "        ny01max = arr[1][1]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "for idx, arr in enumerate(npost01):\n",
    "    if arr[0][0] < nx02min:\n",
    "        nx02min = arr[0][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[0][1] > nx02max:\n",
    "        nx02max = arr[0][1]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][0] < ny02min:\n",
    "        ny02min = arr[1][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][1] > ny02max:\n",
    "        ny02max = arr[1][1]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for idx, val in enumerate(npost01[0]):\n",
    "    x1.append(val[0])\n",
    "    y1.append(val[1])\n",
    "    \n",
    "x2 = []\n",
    "y2 = []\n",
    "for idx, val in enumerate(npost01[1]):\n",
    "    x2.append(val[0])\n",
    "    y2.append(val[1])\n",
    "\n",
    "x1 = np.asarray(x1)\n",
    "x2 = np.asarray(x2)\n",
    "y1 = np.asarray(y1)\n",
    "y2 = np.asarray(y2)\n",
    "\n",
    "print(len(x1))\n",
    "plt.scatter(x1, y1, color='b')\n",
    "plt.scatter(x2, y2, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(state, module):\n",
    "    g = state.g\n",
    "    hierarchy = nx.Graph()\n",
    "    source_target_data = []\n",
    "    nodes = [x for x,y in g.nodes(data=True) if y['module'] == [module]]\n",
    "    node = nodes[0]\n",
    "    for idx, node in enumerate(nodes):\n",
    "        hierarchy_pd = pd.DataFrame(columns=['source', 'target', 'weight', 'level', 'type'])\n",
    "        neighbors = sorted(g[node].items(), key=lambda edge: edge[1]['weight'])\n",
    "        for idx, n in enumerate(neighbors):\n",
    "            #print(\"source: {0}, target: {1}\".format(node, n[0]))\n",
    "            source_node = node\n",
    "            target_node = n[0]\n",
    "            weight = n[1]['weight']\n",
    "            level = idx\n",
    "            if(state.df[state.df['name'] == n[0]]['module'].unique()[0] != module):\n",
    "                type_node = 'exit'\n",
    "                level = -1\n",
    "                print('{0} is an exit node'.format(n[0]))\n",
    "            else:\n",
    "                type_node = 'normal'\n",
    "            source_target_data.append({\n",
    "                \"source\": source_node,\n",
    "                \"target\": target_node,\n",
    "                \"weight\": weight,\n",
    "                \"level\": level,\n",
    "                \"type\": type_node\n",
    "            })\n",
    "    hierarchy_df = pd.DataFrame.from_dict(source_target_data)\n",
    "    print(hierarchy_df.shape)\n",
    "    hierarchy_adjacency = source_target_to_adj_matrix(source_target_data)\n",
    "    state.hg = nx.from_numpy_matrix(hierarchy_adjacency)\n",
    "    pos = hierarchy_pos(state.hg, 1)\n",
    "    nx.draw(state.hg, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "draw_graph(states[0], 'lulesh2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjcency(nodelist):\n",
    "    x_pd = nx.to_pandas_adjacency(g, nodelist=nodes, dtype=int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(G, root=None, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "\n",
    "    '''\n",
    "    From Joel's answer at https://stackoverflow.com/a/29597209/2966723 \n",
    "\n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "\n",
    "    G: the graph (must be a tree)\n",
    "\n",
    "    root: the root node of current branch \n",
    "    - if the tree is directed and this is not given, the root will be found and used\n",
    "    - if the tree is directed and this is given, then the positions will be just for the descendants of this node.\n",
    "    - if the tree is undirected and not given, then a random choice will be used.\n",
    "\n",
    "    width: horizontal space allocated for this branch - avoids overlap with other branches\n",
    "\n",
    "    vert_gap: gap between levels of hierarchy\n",
    "\n",
    "    vert_loc: vertical location of root\n",
    "\n",
    "    xcenter: horizontal location of root\n",
    "    '''\n",
    "    #if not nx.is_tree(G):\n",
    "     #   raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = next(iter(nx.topological_sort(G)))  #allows back compatibility with nx version 1.11\n",
    "        else:\n",
    "            root = random.choice(list(G.nodes))\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "        print(root)\n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "\n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
