{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for gromov distance computation.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groupBy import groupBy\n",
    "from state import State\n",
    "from callgraph import CallGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux path\n",
    "if platform.system() == \"Linux\":\n",
    "\tcallflow_path = \"/home/vidi/Work/llnl/CallFlow/\"\n",
    "else:\n",
    "\t#Mac OSx path\n",
    "\tcallflow_path = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow\"\n",
    "\n",
    "dataset_path = [\"data/lulesh-1/db-ampi4-100-1\", \"data/lulesh-1/db-ampi4-100-8\"]\n",
    "dataset = ['db-ampi4-100-1', 'db-ampi4-100-8']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graphframes.\n",
    "def create_gfs(file_format, paths):    \n",
    "\tprint(\"Creating graphframes....\")                                                                                             \n",
    "\tret = []                                                                                                                         \n",
    "\tfor idx, path in enumerate(paths):\n",
    "\t\tpath = os.path.abspath(os.path.join(callflow_path, path)) \n",
    "\t\tgf = GraphFrame()   \n",
    "\t\tgf.from_hpctoolkit(path)                                                                            \n",
    "\t\tret.append(gf) \n",
    "\t\tprint(str(idx) + \":\" + path)                                                                                              \n",
    "\treturn ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def lookup(df, node):                                                                                                                    \n",
    "\treturn df.loc[df['node'] == node] \n",
    "\n",
    "def lookup_with_name(df, name):\n",
    "\treturn df.loc[df['name'] == name]\n",
    "\n",
    "def getMaxIncTime(gf):                                                                                                                   \n",
    "\tret = 0.0                                                                                                                            \n",
    "\tfor root in gf.graph.roots:                                                                                                          \n",
    "\t\tret = max(ret, lookup(gf.dataframe, root)['time (inc)'].max())                                                           \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "def getMaxExcTime(gf):                                                                                                                   \n",
    "\tret  = gf.dataframe['CPUTIME (usec) (E)'].max()                                                                                      \n",
    "\treturn ret                                                                                                                           \n",
    "\t\t\t   \n",
    "def special_lookup(gf, df_index):   \n",
    "\treturn gf.dataframe.loc[gf.dataframe['name'] == df_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter graphframe and graph\n",
    "def filter_gfs(gfs, filterBy):                                                                                                   \n",
    "\t# Create the graph frames from the paths and corresponding format using hatchet                                                  \n",
    "\tfgfs = []                                                                                                                        \n",
    "\t# Filter graphframes based on threshold                                                                                          \n",
    "\tfor idx, gf in enumerate(gfs):                                                                                              \n",
    "\t\tprint(\"Filtering the dataframe!\")                                                                                         \n",
    "\t\tif filterBy == \"IncTime\":                                                                                          \n",
    "\t\t\tmax_inclusive_time = getMaxIncTime(gf)                                                                             \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if(x['time (inc)'] > 0.01*max_inclusive_time) else False)                   \n",
    "\t\telif self.args.filterBy == \"ExcTime\":                                                                                        \n",
    "\t\t\tmax_exclusive_time = getMaxExcTime(gf)                                                                             \n",
    "\t\t\tprint('[Filter] By Exclusive time = {0})'.format(max_exclusive_time))                                                 \n",
    "\t\t\tfilter_gf = gf.filter(lambda x: True if (x['time'] > 0.01*max_exclusive_time) else False)                  \n",
    "\t\telse:                                                                                                                        \n",
    "\t\t\tprint(\"Not filtering.... Can take forever. Thou were warned\")                                                         \n",
    "\t\t\tfilter_gf = gf                                                                                                           \n",
    "\t\tprint('[Filter] Removed {0} rows.)'.format(gf.dataframe.shape[0] - filter_gf.dataframe.shape[0]))                                                                                                                            \n",
    "\t\tprint(\"Grafting the graph!\")                                                                                            \n",
    "\t\tfilter_gf = filter_gf.squash()                                                                                                \n",
    "\t\tprint(\"[Graft] {0} rows left\".format(filter_gf.dataframe.shape[0])) \n",
    "\t\tfgfs.append(filter_gf)                                              \n",
    "\tprint(fgfs)\n",
    "\treturn fgfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add n_index to the dataframe.\n",
    "def add_n_index(gf):\n",
    "\tgf.dataframe['n_index'] = gf.dataframe.groupby('nid').ngroup()\n",
    "\n",
    "def df_index_name_mapper(graph, df):\n",
    "\tret = {}\n",
    "\tnode_count = 0\n",
    "\troot = graph.roots[0]\n",
    "\tnode_gen = graph.roots[0].traverse()\n",
    "\ttry:\n",
    "\t\twhile root.callpath != None:\n",
    "\t\t\tnode_count += 1\n",
    "\t\t\troot = next(node_gen)\n",
    "\t\t\tret[root.callpath[-1]] = root.df_index\n",
    "\texcept StopIteration:\n",
    "\t\tpass\n",
    "\tfinally:\n",
    "\t\tprint(\"Total nodes in graph: \", node_count)\n",
    "\t\tdel root\n",
    "\treturn ret\n",
    "\n",
    "# add df_index to the dataframe\n",
    "def add_df_index(gf):\n",
    "\tdf_index_name_map = df_index_name_mapper(gf.graph, gf.dataframe)\n",
    "\tgf.dataframe['df_index'] = gf.dataframe['name'].apply(lambda node: df_index_name_map[node] if node in df_index_name_map else 'as ')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callee and caller data into the dataframe\n",
    "def add_callers_and_callee(graph, df):\n",
    "    callees = {}\n",
    "    callers = {}\n",
    "    root = graph.roots[0]\n",
    "    node_gen = graph.roots[0].traverse()\n",
    "    root_df = root.callpath[-1]\n",
    "    callers[root_df] = []\n",
    "    callees[root_df] = []\n",
    "    try:                                                                                                                        \n",
    "        while root.callpath != None:                                                                                            \n",
    "            root = next(node_gen)                                                                                               \n",
    "            if root.parents:                                                                                                     \n",
    "                for idx, parent in enumerate(root.parents):\n",
    "                    root_df = root.callpath[-1]                                                                                     \n",
    "                    parent_df = parent.callpath[-1]                                                                            \n",
    "                    if parent_df not in callees:                                                                                    \n",
    "                        callees[parent_df] = []              \n",
    "                    callees[parent_df].append(root_df)                                                                              \n",
    "                    \n",
    "                    if root_df not in callers:                                                                                      \n",
    "                        callers[root_df] = []                                                                                       \n",
    "                    callers[root_df].append(parent_df)                                                                              \t\n",
    "    except StopIteration:                                                                                                       \n",
    "        pass                                                                                                                    \n",
    "    finally:                                                                                                                    \n",
    "        del root                                                                                                                \n",
    "    \n",
    "    df['callees'] = df['name'].apply(lambda node: callees[node] if node in callees else [])                           \n",
    "    df['callers'] = df['name'].apply(lambda node: callers[node] if node in callers else []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process dataframe to add more information. \n",
    "def preprocess(state):\n",
    "    preprocess = PreProcess.Builder(state).add_df_index().add_n_index().add_mod_index().add_callers_and_callees().add_show_node().add_vis_node_name().update_module_name().clean_lib_monitor().build() \n",
    "\n",
    "#NetworkX stuff.\n",
    "def create_nx_graph(state):\n",
    "\tg = nx.DiGraph()\n",
    "\treturn g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_path):\n",
    "\tdataset = []\n",
    "\tfor idx, path in enumerate(dataset_path):\n",
    "\t\tdataset.append(path.split('/')[0])\n",
    "\n",
    "\tgfs = create_gfs('hpctoolkit', dataset_path)\n",
    "\t# filtered graph frames.\n",
    "\tfgfs = filter_gfs(gfs, 'IncTime')  \n",
    "\treturn fgfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphframes....\n",
      "0:/home/vidi/Work/llnl/CallFlow/data/hpctoolkit-lulesh-2\n",
      "Filtering the dataframe!\n",
      "[Filter] Removed 1204 rows.)\n",
      "Grafting the graph!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vidi/Work/llnl/CallFlow/src/hatchet/hatchet/graphframe.py:176: FutureWarning: 'node' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  num_rows_df = len(self.dataframe.groupby(['node']))\n",
      "/home/vidi/Work/llnl/CallFlow/src/hatchet/hatchet/graphframe.py:268: FutureWarning: 'rank' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  agg_df = new_dataframe.groupby(index_names).agg(agg_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graft] 1274 rows left\n",
      "[<hatchet.graphframe.GraphFrame object at 0x7f195b8b91d0>]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = [\"data/hpctoolkit-lulesh-2\"]\n",
    "fgfs = main(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    states = []\n",
    "    for idx, fgf in enumerate(fgfs):\n",
    "        print(\"Shape of the dataframe from graph ({0}): {1}\".format(dataset[idx], fgf.dataframe.shape))\n",
    "        state = State(fgf)\n",
    "        add_callers_and_callee(state.graph, state.df)\n",
    "#         preprocess(state)\n",
    "#         groupBy(state, 'module')\n",
    "        print(state.df)\n",
    "        states.append(state)\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe from graph (db-ampi4-100-1): (1274, 12)\n",
      "                          time (inc)  time      nid  rank  \\\n",
      "node                rank                                    \n",
      "<program root>      0            nan  0.00     0.00  0.00   \n",
      "main                0            nan  0.00     1.00  0.00   \n",
      "2809:MPI_Finalize   0            nan  0.00 1,233.00  0.00   \n",
      "PMPI_Finalize       0            nan  0.00 1,234.00  0.00   \n",
      "294:MPID_Finalize   0            nan  0.00 1,249.00  0.00   \n",
      "...                              ...   ...      ...   ...   \n",
      "<unknown procedure>              nan   nan      nan   nan   \n",
      "<unknown file>:0                 nan   nan      nan   nan   \n",
      "                                 nan   nan      nan   nan   \n",
      "interp.c:0                       nan   nan      nan   nan   \n",
      "__GI_sched_yield                 nan   nan      nan   nan   \n",
      "\n",
      "                                                                       file  \\\n",
      "node                rank                                                      \n",
      "<program root>      0                                        <unknown file>   \n",
      "main                0     ./src/g/g92/bhatele1/llnl/hpctoolkit/lulesh/lu...   \n",
      "2809:MPI_Finalize   0                                        <unknown file>   \n",
      "PMPI_Finalize       0     /tmp/dpkg-mkdeb.gouoc49UG7/src/mvapich/src/bui...   \n",
      "294:MPID_Finalize   0     /tmp/dpkg-mkdeb.gouoc49UG7/src/mvapich/src/bui...   \n",
      "...                                                                     ...   \n",
      "<unknown procedure>                                                     NaN   \n",
      "<unknown file>:0                                                        NaN   \n",
      "                                                                        NaN   \n",
      "interp.c:0                                                              NaN   \n",
      "__GI_sched_yield                                                        NaN   \n",
      "\n",
      "                          line  \\\n",
      "node                rank         \n",
      "<program root>      0        0   \n",
      "main                0     2690   \n",
      "2809:MPI_Finalize   0        0   \n",
      "PMPI_Finalize       0      271   \n",
      "294:MPID_Finalize   0      137   \n",
      "...                        ...   \n",
      "<unknown procedure>        NaN   \n",
      "<unknown file>:0           NaN   \n",
      "                           NaN   \n",
      "interp.c:0                 NaN   \n",
      "__GI_sched_yield           NaN   \n",
      "\n",
      "                                                                     module  \\\n",
      "node                rank                                                      \n",
      "<program root>      0     /collab/usr/global/tools/hpctoolkit/chaos_5_x8...   \n",
      "main                0      /g/g92/bhatele1/llnl/hpctoolkit/lulesh/lulesh2.0   \n",
      "2809:MPI_Finalize   0     /collab/usr/global/tools/hpctoolkit/chaos_5_x8...   \n",
      "PMPI_Finalize       0     /usr/local/tools/mvapich2-intel-debug-2.2/lib/...   \n",
      "294:MPID_Finalize   0     /usr/local/tools/mvapich2-intel-debug-2.2/lib/...   \n",
      "...                                                                     ...   \n",
      "<unknown procedure>                                                     NaN   \n",
      "<unknown file>:0                                                        NaN   \n",
      "                                                                        NaN   \n",
      "interp.c:0                                                              NaN   \n",
      "__GI_sched_yield                                                        NaN   \n",
      "\n",
      "                                       name               node type  \\\n",
      "node                rank                                              \n",
      "<program root>      0        <program root>     <program root>   PF   \n",
      "main                0                  main               main   PF   \n",
      "2809:MPI_Finalize   0     2809:MPI_Finalize  2809:MPI_Finalize   PF   \n",
      "PMPI_Finalize       0         PMPI_Finalize      PMPI_Finalize   PF   \n",
      "294:MPID_Finalize   0     294:MPID_Finalize  294:MPID_Finalize   PF   \n",
      "...                                     ...                ...  ...   \n",
      "<unknown procedure>                     NaN                NaN  NaN   \n",
      "<unknown file>:0                        NaN                NaN  NaN   \n",
      "                                        NaN                NaN  NaN   \n",
      "interp.c:0                              NaN                NaN  NaN   \n",
      "__GI_sched_yield                        NaN                NaN  NaN   \n",
      "\n",
      "                                                                    callees  \\\n",
      "node                rank                                                      \n",
      "<program root>      0                                                [main]   \n",
      "main                0     [2699:MPI_Init, Loop@lulesh.cc:2771, 2752:Comm...   \n",
      "2809:MPI_Finalize   0                                       [PMPI_Finalize]   \n",
      "PMPI_Finalize       0            [271:MPIR_Barrier_impl, 294:MPID_Finalize]   \n",
      "294:MPID_Finalize   0     [137:MPIR_Comm_release_always, 162:MPIDI_CH3_F...   \n",
      "...                                                                     ...   \n",
      "<unknown procedure>                                                      []   \n",
      "<unknown file>:0                                                         []   \n",
      "                                                                         []   \n",
      "interp.c:0                                                               []   \n",
      "__GI_sched_yield                                                         []   \n",
      "\n",
      "                                      callers  \n",
      "node                rank                       \n",
      "<program root>      0                      []  \n",
      "main                0        [<program root>]  \n",
      "2809:MPI_Finalize   0                  [main]  \n",
      "PMPI_Finalize       0     [2809:MPI_Finalize]  \n",
      "294:MPID_Finalize   0         [PMPI_Finalize]  \n",
      "...                                       ...  \n",
      "<unknown procedure>                        []  \n",
      "<unknown file>:0                           []  \n",
      "                                           []  \n",
      "interp.c:0                                 []  \n",
      "__GI_sched_yield                           []  \n",
      "\n",
      "[1274 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "states = process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph():\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_times = {}\n",
    "for idx, state in enumerate(states):\n",
    "    pivot = pd.pivot_table(state.df, values=['CPUTIME (usec) (I)'], index=['module'], columns=['rank'])\n",
    "    for idx, row in enumerate(pivot.iterrows()):\n",
    "        if(row[0] not in aggr_times):\n",
    "            aggr_times[row[0]] = []\n",
    "        aggr_times[row[0]].append(row[1].mean())\n",
    "print(aggr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = {\n",
    "    \"lulesh2.0\" :{\n",
    "        \"name\" : \"lulesh\",\n",
    "        \"files\" : [ \"mpi-linux-x86_64-ifort-mpicxx/tmp/\", \"mpi-linux-x86_64-ifort-mpicxx/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/ck-libs/\", \"mpi-linux-x86_64-ifort-mpicxx/tmp/libs/conv-libs/\"],\n",
    "        \"functions\" : [] \n",
    "    },\n",
    "    \"libmpi.so.12.0.5\" :{\n",
    "        \"name\" : \"MPI\",\n",
    "        \"files\" : [\"../src/mpi/\"],\n",
    "        \"functions\" : []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(df, keys, metric = 'mean'):\n",
    "    # Groups data by the keys provided\n",
    "    groups = df.groupby(keys)\n",
    "    measure = getattr(groups, metric)\n",
    "    data = measure() \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = states[0].df\n",
    "\n",
    "def rename_module_names(df, props):\n",
    "    module_names = list(props.keys())\n",
    "    for module_name in module_names:\n",
    "        rename_to = props[module_name]['name']\n",
    "        files = props[module_name]['files']\n",
    "        function = props[module_name]['functions']\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.module:\n",
    "                if(row.module == module_name):\n",
    "                    df.set_value(idx, 'module', rename_to)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        print(df['file'].str.contains(files[0], regex=True))\n",
    "\n",
    "    print(df['module'].unique().tolist())\n",
    "\n",
    "\n",
    "rename_module_names(df, props)\n",
    "print(df[df['module']=='Unkno']['name'].unique().tolist())\n",
    "group_df = groupby(df, ['name', 'rank'])\n",
    "print(group_df)\n",
    "for idx, row in df.iterrows():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint plot of the Inclusive and Exclusive times.\n",
    "df = states[0].df\n",
    "df2 = states[1].df\n",
    "root_max_df = 107348942.00\n",
    "root_max_df2 = 145114370.00\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df.loc[(df['time (inc)'] < 0.10*107348942.00) &\n",
    "                     (df['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);\n",
    "sns.jointplot('time (inc)', 'time',\n",
    "              df2.loc[(df2['time (inc)'] < 0.10*145114370.00) &\n",
    "                     (df2['time'] > 0)],\n",
    "              alpha=.25, marker='.', height=8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
