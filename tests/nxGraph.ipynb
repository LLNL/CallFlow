{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import json\n",
    "from ast import literal_eval as make_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets and create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'osu_bw'\n",
    "dir_name = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/src/server/.callflow/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str_with_Node(df, graph):\n",
    "    mapper = {}\n",
    "    def dfs_recurse(root):\n",
    "        for node in root.children: \n",
    "            mapper[node.callpath[-1]] = Node(node.nid, node.callpath, None)\n",
    "            dfs_recurse(node)\n",
    "    for root in graph.roots:\n",
    "        mapper[root.callpath[-1]] = Node(root.nid, root.callpath, None)\n",
    "        dfs_recurse(root)\n",
    "    df['node'] = df['node'].apply(lambda node: mapper[node] if node in mapper else '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gf(name):\n",
    "    state = State()\n",
    "    path = dir_name + name\n",
    "    df_filepath = path + '/group_df.csv'\n",
    "    entire_df_filepath = path + '/entire_df.csv'\n",
    "    graph_filepath = path + '/filter_graph.json'\n",
    "    entire_graph_filepath = path + '/entire_graph.json'   \n",
    "\n",
    "    with open(graph_filepath, 'r') as graphFile:\n",
    "        data = json.load(graphFile)\n",
    "\n",
    "    state.gf = GraphFrame()\n",
    "    state.gf.from_literal(data)\n",
    "\n",
    "    with open(entire_graph_filepath, 'r') as entire_graphFile:\n",
    "        entire_data = json.load(entire_graphFile)\n",
    "            \n",
    "    state.entire_gf = GraphFrame()\n",
    "    state.entire_gf.from_literal(entire_data)\n",
    "\n",
    "    state.df = pd.read_csv(df_filepath)\n",
    "    state.entire_df = pd.read_csv(entire_df_filepath)\n",
    "\n",
    "    state.graph = state.gf.graph\n",
    "    state.entire_graph = state.entire_gf.graph\n",
    "\n",
    "    state.map = state.node_hash_mapper()\n",
    "\n",
    "    # replace df['node'] from str to the Node object.\n",
    "    state.df = replace_str_with_Node(state.df, state.graph)\n",
    "    state.entire_df = replace_str_with_Node(state.entire_df, state.entire_graph)\n",
    "\n",
    "    # add path to the dataframes. \n",
    "    # state.df['path'] = state.df['node'].apply(lambda node: node.callpath)\n",
    "    # state.entire_df['path'] = state.entire_df['node'].apply(lambda node: node.callpath if node else [])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {}\n",
    "states[name] = read_gf(name)\n",
    "df = states['osu_bw'].df\n",
    "graph = states['osu_bw'].graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gets the paths of functions inside the module and converts to a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHierarchyfromdf(state, module):\n",
    "    df = state.df\n",
    "    paths = []\n",
    "    func_in_module = df.loc[df['module'] == module]['name'].unique().tolist()\n",
    "    print(\"Number of functions inside the {0} module: {1}\".format(module, len(func_in_module)))\n",
    "    for idx, func in enumerate(func_in_module):\n",
    "        mean_inc_time = df.loc[df['name'] == func]['time (inc)'].mean()\n",
    "        mean_exc_time = df.loc[df['name'] == func]['time'].mean()\n",
    "        paths.append({\n",
    "            \"module\": module,\n",
    "            \"opath\": df.loc[df['name'] == func]['path'].unique().tolist()[0],\n",
    "            \"path\": df.loc[df['name'] == func]['component_path'].unique().tolist()[0],\n",
    "            \"inc_time\" : df.loc[df['name'] == func]['time (inc)'].mean(),\n",
    "            \"exclusive\" : df.loc[df['name'] == func]['time'].mean(),\n",
    "            \"imbalance_perc\" : df.loc[df['name'] == func]['imbalance_perc'].mean(),\n",
    "            \"component_level\": df.loc[df['name'] == func]['component_level'].unique().tolist()[0],\n",
    "        })\n",
    "    return pd.DataFrame(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In dataset data/lulesh-1/db-ampi4-100-1, there are 4 modules\n",
      "Number of functions inside the <unknown load module> module: 1\n",
      "Number of functions inside the libc-2.17.so module: 2\n",
      "Number of functions inside the lulesh2.0 module: 32\n",
      "Number of functions inside the Unkno module: 50\n",
      "In dataset data/lulesh-1/db-ampi4-100-8, there are 4 modules\n",
      "Number of functions inside the <unknown load module> module: 1\n",
      "Number of functions inside the libc-2.17.so module: 6\n",
      "Number of functions inside the lulesh2.0 module: 36\n",
      "Number of functions inside the Unkno module: 33\n"
     ]
    }
   ],
   "source": [
    "for idx, state in enumerate(states):\n",
    "    modules = state.df['module'].unique().tolist()\n",
    "    print(\"In dataset {0}, there are {1} modules\".format(dataset_path[idx], len(modules)))\n",
    "    for idx, module in enumerate(modules):\n",
    "        paths = getHierarchyfromdf(state, module)\n",
    "        state.paths_df = paths \n",
    "        #paths.to_csv(str(module + \".csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to add data into NxGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_levels(state):\n",
    "    levelMap = {}\n",
    "    track_level = 0\n",
    "    nodes = state.g.nbunch_iter(state.root)\n",
    "    \n",
    "    for start_node in nodes:\n",
    "        print(\"Start node\", start_node)\n",
    "        active_nodes = [start_node]\n",
    "        levelMap[state.root] = 0\n",
    "        \n",
    "        for edge in nx.edge_dfs(state.g, start_node, 'original'):\n",
    "            #rint(\"Edge {0}\".format(edge))\n",
    "            head_level = None\n",
    "            tail_level = None\n",
    "            head, tail = edge[0], edge[1]\n",
    "            \n",
    "            if head != start_node:\n",
    "                active_nodes.append(head)\n",
    "                \n",
    "            if head in active_nodes and head != start_node and tail in active_nodes:\n",
    "                #rint(\"Cycle\", edge)\n",
    "                edge_data = state.g.get_edge_data(*edge)                                                                             \n",
    "                state.g.add_node(tail+'_')                                                                                           \n",
    "                state.g.add_edge(head, tail+'_', data=edge_data)                                                                     \n",
    "                state.g.node[tail+'_']['name'] = [tail + '_']                                                                        \n",
    "                #state.g.node[tail+'_']['weight'] = state.g.node[tail]['weight']   \n",
    "                state.g.remove_edge(edge[0], edge[1])\n",
    "    return levelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def flow_map(state):                                                                                                                 \n",
    "        flowMap = {}                                                                                                                    \n",
    "        nodes = state.g.nbunch_iter(state.root)                                                                                           \n",
    "        for start_node in nodes:                                                                                                        \n",
    "            for edge in nx.edge_dfs(state.g, start_node, 'original'):                                                                    \n",
    "                head_level = None                                                                                                       \n",
    "                tail_level = None                                                                                                       \n",
    "                head, tail = self.tailhead(edge)                                                                                        \n",
    "                                                                                                                                        \n",
    "                # Check if there is an existing level mapping for the head node and assign.                                             \n",
    "                if head in self.level_mapping.keys():                                                                                   \n",
    "                    head_level =  self.level_mapping[head]                                                                              \n",
    "                                                                                                                                        \n",
    "                # Check if there is an existing level mapping for the tail node and assign.                                             \n",
    "                if tail in self.level_mapping.keys():                                                                                   \n",
    "                    tail_level = self.level_mapping[tail]                                                                               \n",
    "                                                                                                                                        \n",
    "                flowMap[(edge[0], edge[1])] = (int(head_level), int(tail_level))                                                        \n",
    "        return flowMap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flows(state):\n",
    "    graph = state.g\n",
    "    ret = {}                                                                                                                                                                                                                                                                          \n",
    "    edges = graph.edges()                                                                                                                                                                                                                                                             \n",
    "    additional_flow = {}                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "    # Calculates the costs in cycles and aggregates to one node.                                                                                                                                                                                                                      \n",
    "    for edge in edges:                                                                                                                                                                                                                                                                \n",
    "        source = edge[0]                                                                                                                                                                                                                                                              \n",
    "        target = edge[1]                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "        if source.endswith('_'):                                                                                                                                                                                                                                                      \n",
    "            cycle_node = source                                                                                                                                                                                                                                                       \n",
    "            cycle_node_df = self.state.lookup_with_nodeName(cycle_node[:-1])                                                                                                                                                                                                      \n",
    "            additional_flow[cycle_node] = cycle_node_df['CPUTIME (usec) (I)'].max()                                                                                                                                                                                                   \n",
    "        elif target.endswith('_'):                                                                                                                                                                                                                                                    \n",
    "            cycle_node = target                                                                                                                                                                                                                                                       \n",
    "            cycle_node_df = state.lookup_with_nodeName(cycle_node[:-1])                                                                                                                                                                                                      \n",
    "            additional_flow[cycle_node] = cycle_node_df['CPUTIME (usec) (I)'].max()                                                                                                                                                                                                   \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "    for edge in edges:                                                                                                                                                                                                                                                                \n",
    "        added_flow = 0                                                                                                                                                                                                                                                                \n",
    "        if edge[0].endswith('_'):                                                                                                                                                                                                                                                     \n",
    "            ret[edge] = additional_flow[edge[0]]                                                                                                                                                                                                                                      \n",
    "            continue                                                                                                                                                                                                                                                                  \n",
    "        elif edge[1].endswith('_'):                                                                                                                                                                                                                                                   \n",
    "            ret[edge] = additional_flow[edge[1]]                                                                                                                                                                                                                                      \n",
    "            continue                                                                                                                                                                                                                                                                  \n",
    "        source = state.lookup_with_nodeName(edge[0])                                                                                                                                                                                                                         \n",
    "        target = state.lookup_with_nodeName(edge[1])                                                                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "        source_inc = source['time (inc)'].max()                                                                                                                                                                                                                               \n",
    "        target_inc = target['time (inc)'].max()                                                                         \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "        if source_inc == target_inc:                                                                                                                                                                                                                                                  \n",
    "            ret[edge] = source_inc                                                                                                                                                                                                                                                    \n",
    "        else:                                                                                                                                                                                                                                                                         \n",
    "            ret[edge] = target_inc    \n",
    "    return ret   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_attributes(state):\n",
    "    capacity_mapping = calculate_flows(state)    \n",
    "    nx.set_edge_attributes(state.g, name='weight', values=capacity_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_map(df, nodes, attr):\n",
    "    ret = {}\n",
    "    for node in nodes:            \n",
    "        if attr == 'time (inc)':\n",
    "            ret[node] = df[df['name'] == node][attr].mean()\n",
    "        else:\n",
    "            ret[node] = df[df['name'] == node][attr].unique().tolist()     \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_attributes(state):\n",
    "    module_mapping = generic_map(state.df, state.g.nodes(), 'module')\n",
    "    nx.set_node_attributes(state.g, name='module', values=module_mapping)\n",
    "    \n",
    "    time_mapping = generic_map(state.df, state.g.nodes(), 'time (inc)')\n",
    "    nx.set_node_attributes(state.g, name='time', values=time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_cycle_path(path):\n",
    "    ret = []\n",
    "    mapper = {}\n",
    "    path = make_tuple(path)\n",
    "    for idx, elem in enumerate(path):\n",
    "        if elem not in mapper:\n",
    "            mapper[elem] = 1\n",
    "            ret.append(elem)\n",
    "        else:\n",
    "            ret.append(elem + \"_\" + str(mapper[elem]))\n",
    "            mapper[elem] += 1\n",
    "    return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paths(state, path_name):\n",
    "    for idx, row in state.df.iterrows():\n",
    "        path = row[path_name]\n",
    "        corrected_path = no_cycle_path(path)\n",
    "        state.g.add_path(corrected_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NxGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nx_graph():\n",
    "    state = states[name]\n",
    "    state.g = nx.DiGraph()\n",
    "    state.root = state.lookup_with_node(state.graph.roots[0])['name'][0]\n",
    "    state.rootInc = state.lookup_with_node(state.graph.roots[0])['time (inc)'].max()\n",
    "        \n",
    "    add_paths(state, 'group_path')\n",
    "#         state.levelMap = add_levels(state)\n",
    "#         add_node_attributes(state)\n",
    "#         add_edge_attributes(state)  \n",
    "    \n",
    "create_nx_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
