{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn.apionly as sns\n",
    "import matplotlib.cm as cm\n",
    "import mpld3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from actions.groupBy import groupBy\n",
    "from state import State\n",
    "from preprocess import PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the directory name according to your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/.callflow\"\n",
    "# dirname = \"/Users/padmanabanke1/CallFlow/.callflow\"\n",
    "# dirname = \"/home/vidi/Work/llnl/CallFlow/.callflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets and create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str_with_Node(df, graph):\n",
    "        mapper = {}\n",
    "        def dfs_recurse(root):\n",
    "            for node in root.children: \n",
    "                mapper[node.callpath[-1]] = Node(node.nid, node.callpath, None)\n",
    "                dfs_recurse(node)\n",
    "        for root in graph.roots:\n",
    "            mapper[root.callpath[-1]] = Node(root.nid, root.callpath, None)\n",
    "            dfs_recurse(root)\n",
    "        df['node'] = df['node'].apply(lambda node: mapper[node] if node in mapper else '')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gf(name):\n",
    "    state = State()\n",
    "    df_filepath = dirname + '/' + name +  '/filter_df.csv'\n",
    "    entire_df_filepath = dirname + '/' + name + '/entire_df.csv'\n",
    "    graph_filepath = dirname + '/' + name + '/filter_graph.json'\n",
    "    entire_graph_filepath = dirname + '/' + name + '/entire_graph.json'   \n",
    "\n",
    "    with open(graph_filepath, 'r') as graphFile:\n",
    "        data = json.load(graphFile)\n",
    "\n",
    "    state.gf = GraphFrame()\n",
    "    state.gf.from_literal(data)\n",
    "\n",
    "    with open(entire_graph_filepath, 'r') as entire_graphFile:\n",
    "        entire_data = json.load(entire_graphFile)\n",
    "            \n",
    "    state.entire_gf = GraphFrame()\n",
    "    state.entire_gf.from_literal(entire_data)\n",
    "\n",
    "    state.df = pd.read_csv(df_filepath)\n",
    "    state.entire_df = pd.read_csv(entire_df_filepath)\n",
    "\n",
    "    state.graph = state.gf.graph\n",
    "    state.entire_graph = state.entire_gf.graph\n",
    "\n",
    "#     state.map = state.node_hash_mapper()\n",
    "\n",
    "    # Print the module group by information. \n",
    "    # print(state.df.groupby(['module']).agg(['mean','count']))\n",
    "\n",
    "    # replace df['node'] from str to the Node object.\n",
    "    state.df = replace_str_with_Node(state.df, state.graph)\n",
    "    state.entire_df = replace_str_with_Node(state.entire_df, state.entire_graph)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calc-pi': <state.State object at 0x1a196ac208>, 'calc-pi-half': <state.State object at 0x1a196ac1d0>, 'calc-pi-random-1': <state.State object at 0x1a196db0b8>}\n"
     ]
    }
   ],
   "source": [
    "# datasets = [\"kripke-mvapich2\", \"kripke-openmpi\"]\n",
    "datasets = ['calc-pi', 'calc-pi-half','calc-pi-random-1']\n",
    "states = {}\n",
    "for idx, dataset_name in enumerate(datasets):\n",
    "    state = read_gf(dataset_name)\n",
    "    states[dataset_name] = state\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to make matplotlib-d3 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        import numpy as np\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "from mpld3 import _display\n",
    "_display.NumpyEncoder = NumpyEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bland altman plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173876.0 173876.0\n",
      "197718.0 197718.0\n",
      "221846.0 221846.0\n",
      "244939.0 244939.0\n",
      "293767.0 293767.0\n",
      "298806.0 298806.0\n",
      "310812.0 310812.0\n",
      "316759.0 316759.0\n",
      "316840.0 316840.0\n",
      "317865.0 317865.0\n",
      "376650.0 376650.0\n",
      "377648.0 377648.0\n",
      "921289.0 921289.0\n",
      "940345.0 940345.0\n",
      "945419.0 945419.0\n",
      "975332.0 975332.0\n",
      "999238.0 999238.0\n",
      "999308.0 999308.0\n",
      "999390.0 999390.0\n",
      "1000306.0 1000306.0\n",
      "162:MPIDI_CH3_Finalize 0.0\n",
      "230:psm_dofinalize 0.0\n",
      "294:MPID_Finalize 0.0\n",
      "36:<unknown procedure> 0.0\n",
      "62:MPI_Finalize 0.0\n",
      "<program root> 0.0\n",
      "<unknown file>:0 143646.91666666666\n",
      "<unknown procedure> 0.0\n",
      "PMPI_Finalize 0.0\n",
      "main 0.0\n"
     ]
    }
   ],
   "source": [
    "group_df = states[datasets[0]].df.groupby(['time (inc)'], sort=True)\n",
    "for idx, g in group_df:\n",
    "    print(idx, g['time (inc)'].mean())\n",
    "    \n",
    "group_df = states[datasets[1]].df.groupby(['name'])\n",
    "for idx, g in group_df:\n",
    "    print(idx, g['time'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, 162:MPIDI_CH3_Finalize to main\n",
      "Data columns (total 13 columns):\n",
      "Unnamed: 0        10 non-null float64\n",
      "rank              10 non-null float64\n",
      "time (inc)        10 non-null float64\n",
      "time              10 non-null float64\n",
      "nid               10 non-null float64\n",
      "rank.1            10 non-null float64\n",
      "line              10 non-null float64\n",
      "n_index           10 non-null float64\n",
      "mod_index         10 non-null float64\n",
      "show_node         10 non-null bool\n",
      "max_incTime       10 non-null float64\n",
      "avg_incTime       10 non-null float64\n",
      "imbalance_perc    10 non-null float64\n",
      "dtypes: bool(1), float64(12)\n",
      "memory usage: 1.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "group_df = states[datasets[1]].df.groupby(['name']).mean()\n",
    "print(group_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkequivalence(gdf1, gdf2, col, catcol):\n",
    "    functions_in_gdf1 = []\n",
    "    functions_in_gdf2 = []\n",
    "    for name, group in gdf1:\n",
    "        functions_in_gdf1.append(name)\n",
    "        \n",
    "    for name, group in gdf2:\n",
    "        functions_in_gdf2.append(name)\n",
    "        \n",
    "    functions = set(functions_in_gdf1) | set(functions_in_gdf2)\n",
    "        \n",
    "    data1 = {}\n",
    "    data2 = {}\n",
    "    for idx, func in enumerate(list(functions)):\n",
    "        # Check if it exists in both. \n",
    "        if func in functions_in_gdf1 and func in functions_in_gdf2:\n",
    "            print('Exist')\n",
    "            data1[func] = gdf1.get_group(func)[col].mean()\n",
    "            data2[func] = gdf2.get_group(func)[col].mean()\n",
    "        # not present in 1st df, and present in 2nd df \n",
    "        elif func not in functions_in_gdf1 and func in functions_in_gdf2:\n",
    "            print('Not in df1')\n",
    "            data1[func] = 0\n",
    "            data2[func] = gdf2.get_group(func)[col].mean()\n",
    "        # present in 1st df and not in 2nd df\n",
    "        elif func in functions_in_gdf1 and func not in functions_in_gdf2:\n",
    "            print('Not in df2')\n",
    "            data1[func] = gdf1.get_group(func)[col].mean()\n",
    "            data2[func] = 0            \n",
    "    data_df1 = pd.DataFrame.from_dict(list(data1.items()))\n",
    "    data_df1.reset_index()\n",
    "    data_df1.columns = ['name', col]\n",
    "    data_df2 = pd.DataFrame.from_dict(list(data2.items()))\n",
    "    data_df2.reset_index()\n",
    "    data_df2.columns = ['name', col]\n",
    "    \n",
    "    return [data_df1, data_df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bland_altman_plot(df1, df2, col, catcol, *args, **kwargs):\n",
    "    gdf1 = df1.groupby(['name'])\n",
    "    gdf2 = df2.groupby(['name'])\n",
    "    temp = checkequivalence(gdf1, gdf2, col, catcol)\n",
    "\n",
    "    data1 = np.asarray(temp[0][col])\n",
    "    data2 = np.asarray(temp[1][col])\n",
    "    print(data1, data2)\n",
    "    labels = np.asarray(temp[0]['name'])\n",
    "    mean      = np.mean([data1, data2], axis=0)\n",
    "    diff      = data1 - data2                   # Difference between data1 and data2\n",
    "    md        = np.mean(diff)                   # Mean of the difference\n",
    "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
    "    print(mean, diff)\n",
    "#     print(gdf2[catcol])\n",
    "#     categories = np.concatenate(np.unique((gdf1[catcol].tolist()), np.unique(gdf2[catcol].tolist())), axis=1)\n",
    "    \n",
    "#     categories = np.unique(gdf1[catcol].tolist())\n",
    "#     colors = cm.rainbow(np.linspace(0, 1, len(categories)))\n",
    "#     colordict = dict(zip(categories, colors))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "#     gdf1[\"Color\"] = gdf1[catcol].apply(lambda x: colordict[x])\n",
    "#     plt.scatter(mean, diff, c=gdf1.Color, *args, **kwargs)\n",
    "    scatter = plt.scatter(diff, mean)\n",
    "    plt.axhline(md,           color='gray', linestyle='--')\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
    "    \n",
    "    ax.grid(color='#aaaaaa', linestyle='solid')\n",
    "    ax.set_title(\"Bland-altman plot\", size=20)\n",
    "        \n",
    "    tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
    "    mpld3.plugins.connect(fig, tooltip)\n",
    "\n",
    "    mpld3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "Exist\n",
      "[     0.    157599.375      0.         0.     26982.125      0.\n",
      "      0.         0.         0.         0.         0.         0.\n",
      "      0.         0.         0.         0.         0.         0.\n",
      "      0.         0.   ] [    0.     78799.6875     0.         0.     13491.0625     0.\n",
      "     0.         0.         0.         0.         0.         0.\n",
      "     0.         0.         0.         0.         0.         0.\n",
      "     0.         0.    ]\n",
      "[     0.      118199.53125      0.           0.       20236.59375\n",
      "      0.           0.           0.           0.           0.\n",
      "      0.           0.           0.           0.           0.\n",
      "      0.           0.           0.           0.           0.     ] [    0.     78799.6875     0.         0.     13491.0625     0.\n",
      "     0.         0.         0.         0.         0.         0.\n",
      "     0.         0.         0.         0.         0.         0.\n",
      "     0.         0.    ]\n",
      "\n",
      "Note: if you're in the IPython notebook, mpld3.show() is not the best command\n",
      "      to use. Consider using mpld3.display(), or mpld3.enable_notebook().\n",
      "      See more information at http://mpld3.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarus/miniconda3/lib/python3.6/site-packages/mpld3/mplexporter/exporter.py:84: UserWarning: Blended transforms not yet supported. Zoom behavior may not work as expected.\n",
      "  warnings.warn(\"Blended transforms not yet supported. \"\n",
      "127.0.0.1 - - [21/Aug/2019 13:52:52] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2019 13:52:52] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2019 13:52:53] \"GET /mpld3.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "bland_altman_plot(states[datasets[0]].entire_df, states[datasets[1]].entire_df, 'time', 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
