{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/miniconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory.\n",
      "  self[key] = other[key]\n",
      "/home/suraj/miniconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = other[key]\n",
      "/home/suraj/miniconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  self[key] = other[key]\n",
      "/home/suraj/miniconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = other[key]\n",
      "/home/suraj/miniconda3/lib/python3.7/_collections_abc.py:841: MatplotlibDeprecationWarning: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = other[key]\n",
      "/home/suraj/miniconda3/lib/python3.7/site-packages/seaborn/apionly.py:9: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "from hatchet import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn.apionly as sns\n",
    "import platform\n",
    "import json\n",
    "from ast import literal_eval as make_tuple\n",
    "import matplotlib.cm as cm\n",
    "import utils\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for gromov distance computation.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "# import ot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from actions.groupBy import groupBy\n",
    "from state import State\n",
    "from preprocess import PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 10\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = (16, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        import numpy as np\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "from mpld3 import _display\n",
    "_display.NumpyEncoder = NumpyEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the directory name according to your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/.callflow\"\n",
    "# dirname = \"/Users/padmanabanke1/CallFlow/.callflow\"\n",
    "# dirname = \"/home/vidi/Work/llnl/CallFlow/.callflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets and create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str_with_Node(df, graph):\n",
    "        mapper = {}\n",
    "        def dfs_recurse(root):\n",
    "            for node in root.children: \n",
    "                mapper[node.callpath[-1]] = Node(node.nid, node.callpath, None)\n",
    "                dfs_recurse(node)\n",
    "        for root in graph.roots:\n",
    "            mapper[root.callpath[-1]] = Node(root.nid, root.callpath, None)\n",
    "            dfs_recurse(root)\n",
    "        df['node'] = df['node'].apply(lambda node: mapper[node] if node in mapper else '')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gf(name):\n",
    "    state = State()\n",
    "    df_filepath = dirname + '/' + name +  '/filter_df.csv'\n",
    "    entire_df_filepath = dirname + '/' + name + '/entire_df.csv'\n",
    "    graph_filepath = dirname + '/' + name + '/filter_graph.json'\n",
    "    entire_graph_filepath = dirname + '/' + name + '/entire_graph.json'   \n",
    "\n",
    "    with open(graph_filepath, 'r') as graphFile:\n",
    "        data = json.load(graphFile)\n",
    "\n",
    "    state.gf = GraphFrame()\n",
    "    state.gf.from_literal(data)\n",
    "\n",
    "    with open(entire_graph_filepath, 'r') as entire_graphFile:\n",
    "        entire_data = json.load(entire_graphFile)\n",
    "            \n",
    "    state.entire_gf = GraphFrame()\n",
    "    state.entire_gf.from_literal(entire_data)\n",
    "\n",
    "    state.df = pd.read_csv(df_filepath)\n",
    "    state.entire_df = pd.read_csv(entire_df_filepath)\n",
    "\n",
    "    state.graph = state.gf.graph\n",
    "    state.entire_graph = state.entire_gf.graph\n",
    "\n",
    "#     state.map = state.node_hash_mapper()\n",
    "\n",
    "    # Print the module group by information. \n",
    "    # print(state.df.groupby(['module']).agg(['mean','count']))\n",
    "\n",
    "    # replace df['node'] from str to the Node object.\n",
    "    state.df = replace_str_with_Node(state.df, state.graph)\n",
    "    state.entire_df = replace_str_with_Node(state.entire_df, state.entire_graph)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/.callflow/calc-pi/filter_graph.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-648bc1a17176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_gf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-be3c02eee7f0>\u001b[0m in \u001b[0;36mread_gf\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mentire_graph_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/entire_graph.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgraphFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jarus/ucd/Research/Visualisation/projects/CallFlow/.callflow/calc-pi/filter_graph.json'"
     ]
    }
   ],
   "source": [
    "# datasets = [\"kripke-mvapich2\", \"kripke-openmpi\"]\n",
    "datasets = ['calc-pi', 'calc-pi-half','calc-pi-random-1']\n",
    "states = {}\n",
    "for idx, dataset_name in enumerate(datasets):\n",
    "    state = read_gf(dataset_name)\n",
    "    states[dataset_name] = state\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create networkx graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_with_name(df, name):\n",
    "    return df.loc[df['name'] == name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_paths(state, path_name):\n",
    "    for idx, row in state.df.iterrows():\n",
    "        if row.show_node:\n",
    "            path = row[path_name]\n",
    "            if isinstance(path, str):\n",
    "                path = make_tuple(row[path_name])\n",
    "            state.g.add_path(path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_map(df, nodes, attr):\n",
    "    ret = {}\n",
    "    for node in nodes: \n",
    "        if attr == 'time (inc)':\n",
    "            ret[node] = df[df['name'] == node][attr].mean()\n",
    "        else:\n",
    "            ret[node] = df[df['name'] == node][attr].unique().tolist()     \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flows(state):\n",
    "    graph = state.g\n",
    "    ret = {}                                                                                                                                                                                                                                                                          \n",
    "    edges = graph.edges()                                                                                                                                                                                                                                                             \n",
    "    additional_flow = {}                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "    # Calculates the costs in cycles and aggregates to one node.                                                                                                                                                                                                                      \n",
    "    for edge in edges:                                                                                                                                                                                                                                                                \n",
    "        source = edge[0]                                                                                                                                                                                                                                                              \n",
    "        target = edge[1]                                                                                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                                \n",
    "    for edge in edges:                                                                                                                                                                                                                                                                \n",
    "        added_flow = 0                                                                                                                                                                                                                                                                \n",
    "        if edge[0].endswith('_'):                                                                                                                                                                                                                                                     \n",
    "            ret[edge] = additional_flow[edge[0]]                                                                                                                                                                                                                                      \n",
    "            continue                                                                                                                                                                                                                                                                  \n",
    "        elif edge[1].endswith('_'):                                                                                                                                                                                                                                                   \n",
    "            ret[edge] = additional_flow[edge[1]]                                                                                                                                                                                                                                      \n",
    "            continue                                                                                                                                                                                                                                                                  \n",
    "        source = lookup_with_name(state.df, edge[0])                                                                                                                                                                                                                         \n",
    "        target = lookup_with_name(state.df, edge[1])                                                                                                                                                                                                                         \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "        source_inc = source['time (inc)'].max()                                                                                                                                                                                                                               \n",
    "        target_inc = target['time (inc)'].max()                                                                         \n",
    "                                                                                                                                                                                                                                                                                          \n",
    "        if source_inc == target_inc:                                                                                                                                                                                                                                                  \n",
    "            ret[edge] = source_inc                                                                                                                                                                                                                                                    \n",
    "        else:                                                                                                                                                                                                                                                                         \n",
    "            ret[edge] = target_inc    \n",
    "    return ret   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_attributes(state):\n",
    "    capacity_mapping = calculate_flows(state)    \n",
    "    nx.set_edge_attributes(state.g, name='weight', values=capacity_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_attributes(state):\n",
    "    module_mapping = generic_map(state.df, state.g.nodes(), 'module')\n",
    "    nx.set_node_attributes(state.g, name='module', values=module_mapping)\n",
    "    \n",
    "    time_mapping = generic_map(state.df, state.g.nodes(), 'time (inc)')\n",
    "    nx.set_node_attributes(state.g, name='time (inc)', values=time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nx_graph(states):\n",
    "    for idx, state_name in enumerate(states):\n",
    "        state = states[state_name]\n",
    "        state.g = nx.DiGraph()\n",
    "        root_df = lookup_with_name(state.df, state.graph.roots[0].callpath[-1])\n",
    "        state.root = root_df['name'].tolist()[0]\n",
    "        state.rootInc = root_df['time (inc)'].max()\n",
    "        add_paths(state, 'path')\n",
    "#         state.levelMap = add_levels(state)\n",
    "        add_node_attributes(state)\n",
    "        add_edge_attributes(state)  \n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "states = create_nx_graph(states)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flow_matrix(state, module):\n",
    "    g = state.g\n",
    "    all_nodes = g.nodes(data=True)\n",
    "#     nod = [(x,y) for x, y in g.nodes(data=True)]\n",
    "    nodes = [x for x,y in g.nodes(data=True) if y['module'] == [module]]\n",
    "    print(nodes)\n",
    "    # nodesInModule = filter(lambda (n, d): d['module'] == start_node, g.nodes(data=True))\n",
    "    state.nodeKey = {}\n",
    "    for idx, node in enumerate(nodes):\n",
    "        state.nodeKey[node[0]] = idx\n",
    "    \n",
    "    flow_matrix = np.zeros(shape=(len(nodes),len(nodes)))\n",
    "    flow_matrix.astype(float)\n",
    "    root_inc = g.node[nodes[0]]['time (inc)']\n",
    "    print(root_inc)\n",
    "#     root_inc = 194595257.0\n",
    "    \n",
    "    for idx, node in enumerate(nodes):\n",
    "        print(g[node].items())\n",
    "#         neighbors = sorted(g[node].items(), key=lambda edge: edge[0]['weight'])\n",
    "#         print(neighbors)\n",
    "        neighbors = sorted(g[node].items(), key=lambda edge: edge[1]['weight'])\n",
    "        print(neighbors)\n",
    "        for idx, n in enumerate(neighbors):\n",
    "            sourceKey = int(state.nodeKey[node])\n",
    "#            print(state.df[state.df['node' == n[0]]])\n",
    "            targetKey = int(state.nodeKey[n[0]])\n",
    "            weight = n[1]['weight']\n",
    "            flow_matrix[sourceKey][targetKey] = n[1]['weight']/(1.0*root_inc)\n",
    "    print(flow_matrix)\n",
    "    return flow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'calc-pi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e247056884a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentire_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'libmpi.so.12.0.5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# module = 'Unknown(NA)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'libmonitor.so.0.0.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflow_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'calc-pi'"
     ]
    }
   ],
   "source": [
    "print(states[datasets[0]].entire_df['module'].unique())\n",
    "module = 'libmpi.so.12.0.5'\n",
    "# module = 'Unknown(NA)'\n",
    "module = 'libmonitor.so.0.0.0'\n",
    "flow_matrices = []\n",
    "for idx, state in enumerate(states):\n",
    "    flow_matrix = create_flow_matrix(states[state], module)\n",
    "    flow_matrices.append(flow_matrix)\n",
    "#     plt.matshow(flow_matrix)\n",
    "fm = np.array([flow_matrices[0], flow_matrices[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(variable):\n",
    "    n_bins = 2\n",
    "    N, bins, patches = plt.hist(variable, bins=n_bins)\n",
    "    #fracs = N / N.max()\n",
    "    #norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "    #for thisfrac, thispatch in zip(fracs, patches):\n",
    "    #    color = plt.cm.viridis(norm(thisfrac))\n",
    "    #    thispatch.set_facecolor(color)\n",
    "    #plt.yaxis.set_major_formatter(PercentFormatter(xmax=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Spatial distance between each node in the flow matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7848d39e3dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ot' is not defined"
     ]
    }
   ],
   "source": [
    "S = len(states) - 1\n",
    "\n",
    "n_samples = 40\n",
    "ns = [len(fm[s]) for s in range(S)]\n",
    "\n",
    "Cs = [sp.spatial.distance.cdist(fm[s], fm[s]) for s in range(S)]\n",
    "Cs = [cs / cs.max() for cs in Cs]\n",
    "\n",
    "ps = [ot.unif(ns[s]) for s in range(S)]\n",
    "p = ot.unif(n_samples)\n",
    "\n",
    "histogram(p)\n",
    "\n",
    "histogram(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gromov wassertstein barycenter calculation\n",
    "\n",
    "By barycenter they mean the design of an “average” or barycenter of similarity matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(variable):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.plot(variable[0], variable[1], 'o', label=str(variable))\n",
    "    \n",
    "    tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
    "    mpld3.plugins.connect(fig, tooltip)\n",
    "    mpld3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smacof_mds(C, dim, max_iter=3000, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Returns an interpolated point cloud following the dissimilarity matrix C\n",
    "    using SMACOF multidimensional scaling (MDS) in specific dimensionned\n",
    "    target space\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C : ndarray, shape (ns, ns)\n",
    "        dissimilarity matrix\n",
    "    dim : int\n",
    "          dimension of the targeted space\n",
    "    max_iter :  int\n",
    "        Maximum number of iterations of the SMACOF algorithm for a single run\n",
    "    eps : float\n",
    "        relative tolerance w.r.t stress to declare converge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npos : ndarray, shape (R, dim)\n",
    "           Embedded coordinates of the interpolated point cloud (defined with\n",
    "           one isometry)\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.RandomState(seed=3)\n",
    "\n",
    "    mds = manifold.MDS(\n",
    "        dim,\n",
    "        max_iter=max_iter,\n",
    "        eps=1e-9,\n",
    "        dissimilarity='precomputed',\n",
    "        \n",
    "        n_init=1)\n",
    "    pos = mds.fit(C).embedding_\n",
    "\n",
    "    nmds = manifold.MDS(\n",
    "        2,\n",
    "        max_iter=max_iter,\n",
    "        eps=1e-9,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        random_state=rng,\n",
    "        n_init=1)\n",
    "    npos = nmds.fit_transform(C, init=pos)\n",
    "\n",
    "    return npos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdast = [[float(i) / 3, float(3 - i) / 3] for i in [1, 2]]\n",
    "Ct01 = [0 for i in range(2)]\n",
    "for i in range(S):\n",
    "    Ct01[i] = ot.gromov.gromov_barycenters(n_samples, [Cs[0], Cs[1]],\n",
    "                                           [ps[0], ps[1]\n",
    "                                            ], p, lambdast[i], 'square_loss',  # 5e-4,\n",
    "                                           max_iter=100, tol=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = PCA(n_components=2)\n",
    "npos = [0, 0]\n",
    "npos = [smacof_mds(Cs[s], 2) for s in range(S)]\n",
    "\n",
    "npost01 = [0, 0]\n",
    "npost01 = [smacof_mds(Ct01[s], 2) for s in range(2)]\n",
    "npost01 = [clf.fit_transform(npost01[s]) for s in range(2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Ct01[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(Ct01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(npost01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx01min = npos[0][0][0]\n",
    "nx01max = npos[0][0][0]\n",
    "ny01min = npos[0][1][1]\n",
    "ny01max = npos[0][1][1]\n",
    "\n",
    "nx02min = npos[1][0][0]\n",
    "nx02max = npos[1][0][0]\n",
    "ny02min = npos[1][1][1]\n",
    "ny02max = npos[1][1][1]\n",
    "\n",
    "for idx, arr in enumerate(npos):\n",
    "    if arr[0][0] < nx01min:\n",
    "        nx01min = arr[0][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[0][1] > nx01max:\n",
    "        nx01max = arr[0][1]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][0] < ny01min:\n",
    "        ny01min = arr[1][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][1] > ny01max:\n",
    "        ny01max = arr[1][1]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "for idx, arr in enumerate(npost01):\n",
    "    if arr[0][0] < nx02min:\n",
    "        nx02min = arr[0][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[0][1] > nx02max:\n",
    "        nx02max = arr[0][1]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][0] < ny02min:\n",
    "        ny02min = arr[1][0]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if arr[1][1] > ny02max:\n",
    "        ny02max = arr[1][1]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "x1 = []\n",
    "y1 = []\n",
    "for idx, val in enumerate(npost01[0]):\n",
    "    x1.append(val[0])\n",
    "    y1.append(val[1])\n",
    "    \n",
    "x2 = []\n",
    "y2 = []\n",
    "for idx, val in enumerate(npost01[1]):\n",
    "    x2.append(val[0])\n",
    "    y2.append(val[1])\n",
    "\n",
    "x1 = np.asarray(x1)\n",
    "x2 = np.asarray(x2)\n",
    "y1 = np.asarray(y1)\n",
    "y2 = np.asarray(y2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = plt.scatter(x1, y1, color='b')\n",
    "scatter = plt.scatter(x2, y2, color='r')\n",
    "\n",
    "ax.grid(color='#aaaaaa', linestyle='solid')\n",
    "ax.set_title(\"Gromov wasserstein barycenter\", size=20)\n",
    "        \n",
    "tooltip = mpld3.plugins.PointLabelTooltip(scatter, labels=labels)\n",
    "mpld3.plugins.connect(fig, tooltip)\n",
    "\n",
    "mpld3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(state, module):\n",
    "    g = state.g\n",
    "    hierarchy = nx.Graph()\n",
    "    source_target_data = []\n",
    "    nodes = [x for x,y in g.nodes(data=True) if y['module'] == [module]]\n",
    "    node = nodes[0]\n",
    "    for idx, node in enumerate(nodes):\n",
    "        hierarchy_pd = pd.DataFrame(columns=['source', 'target', 'weight', 'level', 'type'])\n",
    "        neighbors = sorted(g[node].items(), key=lambda edge: edge[1]['weight'])\n",
    "        for idx, n in enumerate(neighbors):\n",
    "            #print(\"source: {0}, target: {1}\".format(node, n[0]))\n",
    "            source_node = node\n",
    "            target_node = n[0]\n",
    "            weight = n[1]['weight']\n",
    "            level = idx\n",
    "            if(state.df[state.df['name'] == n[0]]['module'].unique()[0] != module):\n",
    "                type_node = 'exit'\n",
    "                level = -1\n",
    "                print('{0} is an exit node'.format(n[0]))\n",
    "            else:\n",
    "                type_node = 'normal'\n",
    "            source_target_data.append({\n",
    "                \"source\": source_node,\n",
    "                \"target\": target_node,\n",
    "                \"weight\": weight,\n",
    "                \"level\": level,\n",
    "                \"type\": type_node\n",
    "            })\n",
    "    hierarchy_df = pd.DataFrame.from_dict(source_target_data)\n",
    "    print(hierarchy_df.shape)\n",
    "    hierarchy_adjacency = source_target_to_adj_matrix(source_target_data)\n",
    "    state.hg = nx.from_numpy_matrix(hierarchy_adjacency)\n",
    "    pos = hierarchy_pos(state.hg, 1)\n",
    "    nx.draw(state.hg, pos=pos, with_labels=True)\n",
    "    plt.show()\n",
    "\n",
    "draw_graph(states[0], 'lulesh2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjcency(nodelist):\n",
    "    x_pd = nx.to_pandas_adjacency(g, nodelist=nodes, dtype=int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(G, root=None, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "\n",
    "    '''\n",
    "    From Joel's answer at https://stackoverflow.com/a/29597209/2966723 \n",
    "\n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "\n",
    "    G: the graph (must be a tree)\n",
    "\n",
    "    root: the root node of current branch \n",
    "    - if the tree is directed and this is not given, the root will be found and used\n",
    "    - if the tree is directed and this is given, then the positions will be just for the descendants of this node.\n",
    "    - if the tree is undirected and not given, then a random choice will be used.\n",
    "\n",
    "    width: horizontal space allocated for this branch - avoids overlap with other branches\n",
    "\n",
    "    vert_gap: gap between levels of hierarchy\n",
    "\n",
    "    vert_loc: vertical location of root\n",
    "\n",
    "    xcenter: horizontal location of root\n",
    "    '''\n",
    "    #if not nx.is_tree(G):\n",
    "     #   raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = next(iter(nx.topological_sort(G)))  #allows back compatibility with nx version 1.11\n",
    "        else:\n",
    "            root = random.choice(list(G.nodes))\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "        print(root)\n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "\n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
