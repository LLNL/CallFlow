{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallFlow interface demo\n",
    "CallFlow exposes a Python package callflow that provides functionality to load and manipulate callgraphs.\n",
    "\n",
    "CallFlow is structured as three components:\n",
    "\n",
    "* A Python package callflow that provides functionality to load and manipulate callgraphs.\n",
    "* A D3 based app for visualization.\n",
    "* A python server to support the visualization client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hatchet as ht\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CallFlow imports\n",
    "import callflow\n",
    "from callflow import CallFlow\n",
    "from callflow.operations import ArgParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CallFlow Python package\n",
    "In particular, CallFlow exposes 4 main classes to handle data structures.\n",
    "* <strong>GraphFrame</strong> - contains Hatchet's GraphFrame along with some functionality that callflow introduces. (e.g., nxGraph).\n",
    "* <strong>CallFlow</strong> - to interface between the client API endpoints and other functionality.\n",
    "* <strong>SuperGraph</strong> - to handle processing of a an input dataset.\n",
    "* <strong>EnsembleSuperGraph</strong> - to handle processing of an ensemble of datasets\n",
    "\n",
    "In addition, it exposes a set of modules whose functionality could be useful.\n",
    "* <strong> algorithms </strong> - Algorithms to compute similarity (graph) using distance metrics and DR calculation.\n",
    "* <strong> layout </strong> - Computes a nxGraph output based on the layout desired (e.g., node-link for CCT, Sankey for supergraph, and icicle plot for module hierarchy. \n",
    "* <strong> modules </strong> - Exposes interactions performed in callflow (e.g., splitting, hierarchy, histograms, scatterplot, box plots, etc. All of them are exposed as API endpoints that can be queried using sockets. \n",
    "* <strong> operations </strong> - Filter, group and union operation on single/ensemble of graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CallFlow',\n",
       " 'EnsembleGraph',\n",
       " 'GraphFrame',\n",
       " 'SuperGraph',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_load_ipython_extension',\n",
       " 'algorithms',\n",
       " 'callflow',\n",
       " 'datastructures',\n",
       " 'get_logger',\n",
       " 'init_logger',\n",
       " 'layout',\n",
       " 'load_ipython_extension',\n",
       " 'logger',\n",
       " 'modules',\n",
       " 'operations',\n",
       " 'server',\n",
       " 'timer',\n",
       " 'utils']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(callflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need a config file that specifies the files to be loaded into the interface. We plan to remove this step next and automate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single dataset --config mode\n",
    "config_file = os.path.abspath(\"../data/hpctoolkit-cpi-databases/callflow.config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single dataset --data_dir mode\n",
    "data_dir = os.path.abspath(\"../data/caliper-cali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the profile format\n",
    "profile_format = \"hpctoolkit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConfigFileReader is a module that helps process the provided config JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jarus/Work/llnl/CallFlow/data/caliper-cali/.callflow/callflow.config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e074c363deae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read config file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--data_dir \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" --profile_format \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprofile_format\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" --process\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# cargs = ArgParser(\"--config \" + config_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/llnl/CallFlow/callflow/operations/argparser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args_string)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Write the config file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mArgParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# validate the config variable by checking with the schema.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/llnl/CallFlow/callflow/operations/argparser.py\u001b[0m in \u001b[0;36m_write_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"callflow.config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callflow.config.json dumped into {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jarus/Work/llnl/CallFlow/data/caliper-cali/.callflow/callflow.config.json'"
     ]
    }
   ],
   "source": [
    "# Read config file.\n",
    "args = ArgParser(\"--data_dir \" + data_dir + \" --profile_format \" + profile_format)\n",
    "# cargs = ArgParser(\"--config \" + config_file) \n",
    "args.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1b8e77469b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cargs' is not defined"
     ]
    }
   ],
   "source": [
    "cargs.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, I will be focusing on what the `CallFlow` class exposes. First step is to create a callflow object. The parameter, `ensemble` determines whether CallFlow loads a 'single' or 'ensemble' version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scf = CallFlow(config=args.config, ensemble=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing datasets\n",
    "Processing step creates a `.callflow` directory that contains all the processed information. `.callflow` directory is placed in the `save_path` provided using the `config` file.\n",
    "\n",
    "* .callflow\n",
    "    * dataset1\n",
    "        * auxiliary_data.json \n",
    "        * df.csv (contains dataframe)\n",
    "        * nxg.json (contains nxGraph)\n",
    "    * ...dataset\n",
    "    * ensemble\n",
    "        * auxiliary_data.json\n",
    "        * df.csv (contains dataframe)\n",
    "        * nxg.json (contains nxGraph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the supergraphs.\n",
    "if the preprocessing is already done, we can directly load the supergraphs from `.callflow` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf.supergraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, `SuperGraph` class contains the Hatchet's GraphFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(scf.supergraphs['hpctoolkit-cpi-database-base'].gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket requests\n",
    "The socket endpoints are exposed using `request_single` and `request_ensemble` function calls. Both these calls require an input object that specifies what action to perform on the data. \n",
    "\n",
    "```\n",
    "{\n",
    "    \"name\": String // action to perform, required.\n",
    "    \"dataset\": Array // datasets to perform the action.\n",
    "    ...other attributes // Each request has its own set of parameters that are required.\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"name\": \"cct\", \"dataset\": \"hpctoolkit-cpi-database-base\", \"functionsInCCT\": 50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scct = scf.request_single(payload)\n",
    "print(f\"Nodes (count = {len(scct.nodes())}) are: {scct.nodes(data=True)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Edges (count = {len(scct.edges())}) are: {scct.edges(data=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary information\n",
    "\n",
    "Auxiliary information contains per-callsite and per-module information, that makes it feasible to posses the information for interactions that are performed using CallFlow, in place rather than querying frequently to the server. \n",
    "\n",
    "PS: This could lead to huge JSONs for large HPCtoolkit data. To avoid this, I have implemented a faster lookup/fetch using HDF5 to create per-callsite and per-module storage. But this feature is not part of master yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "auxiliary = scf.request_single({\"name\": \"auxiliary\", \"dataset\": \"hpctoolkit-cpi-database-base\"})\n",
    "print(auxiliary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SuperGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssg = scf.request_single({\"name\": \"supergraph\", \"groupBy\": \"module\", \"dataset\":\"hpctoolkit-cpi-database-base\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nodes (count = {len(ssg.nodes())}) are: {ssg.nodes(data=False)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Edges (count = {len(ssg.edges())}) are: {ssg.edges(data=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
